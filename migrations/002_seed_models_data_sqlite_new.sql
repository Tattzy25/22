-- Seed data for AI Gateway models (from CSV data)
-- NOTE: This seed data is from the actual Model_Catalog__Parsed_.csv file
-- Models and providers listed here are from the official catalog

-- Insert unique models
INSERT OR IGNORE INTO models (id, name, category, capabilities, description, context_window, response_time) VALUES
  ('anthropic-claude-sonnet-4', 'claude-sonnet-4', 'General / Reasoning', '["Code generation"]', 'Claude Sonnet 4 significantly improves on Sonnet 3.7''s industry-leading capabilities, excelling in coding with a state-of-the-art 72.7% on SWE-bench. The model balances performance and efficiency for internal and external use cases, with enhanced steerability for greater control over implementations. While not matching Opus 4 in most domains, it delivers an optimal mix of capability and practicality.', '200K', '< 30 seconds'),
  ('openai-gpt-5', 'gpt-5', 'General / Reasoning', '["Advanced reasoning", "Code generation"]', 'GPT-5 is OpenAI''s flagship language model that excels at complex reasoning, broad real-world knowledge, code-intensive, and multi-step agentic tasks.', '400K', '< 30 seconds'),
  ('google-gemini-2-0-flash', 'gemini-2.0-flash', 'General / Reasoning', '["Multimodal", "Fast responses"]', 'Gemini 2.0 Flash delivers next-gen features and improved capabilities, including superior speed, built-in tool use, multimodal generation, and a 1M token context window.', '1M', '< 10 seconds'),
  ('openai-gpt-4-1-nano', 'gpt-4.1-nano', 'General / Reasoning', '["Fast responses", "Cost-effective"]', 'GPT-4.1 nano is the fastest, most cost-effective GPT 4.1 model.', '1M', '< 10 seconds'),
  ('openai-gpt-5-mini', 'gpt-5-mini', 'General / Reasoning', '["Advanced reasoning", "Fast responses", "Cost-effective"]', 'GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.', '400K', '< 30 seconds'),
  ('google-gemini-2-5-pro', 'gemini-2.5-pro', 'General / Reasoning', '["Multimodal", "Advanced reasoning"]', 'Gemini 2.5 Pro is our most advanced reasoning Gemini model, capable of solving complex problems. It features a 2M token context window and supports multimodal inputs including text, images, audio, video, and PDF documents.', '1M', '< 30 seconds'),
  ('google-gemini-2-5-flash', 'gemini-2.5-flash', 'General / Reasoning', '["Multimodal"]', 'Gemini 2.5 Flash is a thinking model that offers great, well-rounded capabilities. It is designed to offer a balance between price and performance with multimodal support and a 1M token context window.', '1M', '< 10 seconds'),
  ('google-gemini-2-5-flash-lite', 'gemini-2.5-flash-lite', 'General / Reasoning', '["Multimodal", "Code generation"]', 'Gemini 2.5 Flash-Lite is a balanced, low-latency model with configurable thinking budgets and tool connectivity (e.g., Google Search grounding and code execution). It supports multimodal input and offers a 1M-token context window.', '1M', '< 10 seconds'),
  ('openai-gpt-4-1', 'gpt-4.1', 'General / Reasoning', '["Advanced reasoning"]', 'GPT 4.1 is OpenAI''s flagship model for complex tasks. It is well suited for problem solving across domains.', '1M', '< 30 seconds'),
  ('openai-text-embedding-3-small', 'text-embedding-3-small', 'Embedding', '["General purpose"]', 'OpenAI''s improved, more performant version of their ada embedding model. Input Tokens $0.02/M azure logo openai logo Available on 2 providers openai logo', '', 'Instant'),
  ('openai-gpt-4-1-mini', 'gpt-4.1-mini', 'General / Reasoning', '["Fast responses", "Cost-effective"]', 'GPT 4.1 mini provides a balance between intelligence, speed, and cost that makes it an attractive model for many use cases.', '1M', '< 30 seconds'),
  ('anthropic-claude-3-7-sonnet', 'claude-3.7-sonnet', 'General / Reasoning', '["Advanced reasoning", "Code generation"]', 'Claude 3.7 Sonnet is the first hybrid reasoning model and Anthropic''s most intelligent model to date. It delivers state-of-the-art performance for coding, content generation, data analysis, and planning tasks, building upon its predecessor Claude 3.5 Sonnet''s capabilities in software engineering and computer use.', '200K', '< 30 seconds'),
  ('openai-gpt-5-nano', 'gpt-5-nano', 'General / Reasoning', '["General purpose"]', 'GPT-5 nano is a high throughput model that excels at simple instruction or classification tasks.', '400K', '< 10 seconds'),
  ('deepseek-deepseek-v3-1', 'deepseek-v3.1', 'General / Reasoning', '["General purpose"]', 'DeepSeek-V3.1 is post-trained on the top of DeepSeek-V3.1-Base, which is built upon the original V3 base checkpoint through a two-phase long context extension approach, following the methodology outlined in the original DeepSeek-V3 report. DeepSeek has expanded their dataset by collecting additional long documents and substantially extending both training phases.', '164K', '< 30 seconds'),
  ('openai-gpt-4o', 'gpt-4o', 'General / Reasoning', '["Advanced reasoning", "Fast responses"]', 'GPT-4o from OpenAI has broad general knowledge and domain expertise allowing it to follow complex instructions in natural language and solve difficult problems accurately. It matches GPT-4 Turbo performance with a faster and cheaper API.', '128K', '< 30 seconds'),
  ('moonshotai-kimi-k2-0905', 'kimi-k2-0905', 'General / Reasoning', '["Code generation"]', 'Kimi K2 0905 is an updated version of Kimi K2, a state-of-the-art mixture-of-experts (MoE) language model with 32 billion activated parameters and 1 trillion total parameters. Kimi K2 0905 has improved coding abilities, a longer context window, and agentic tool use, and a longer (262K) context window.', '256K', '< 30 seconds'),
  ('moonshotai-kimi-k2', 'kimi-k2', 'General / Reasoning', '["Code generation"]', 'State of the art language model for agentic and coding tasks', '131K', '< 30 seconds'),
  ('alibaba-qwen3-coder', 'qwen3-coder', 'Coding / Code-Assist', '["Code generation", "Cost-effective"]', 'Qwen3 Coder 480B is a specialized programming model designed for ultra-efficient agentic code generation with long context and state-of-the-art performance. It excels at writing, debugging, and explaining code across multiple programming languages.', '131K', '< 30 seconds'),
  ('anthropic-claude-opus-4-1', 'claude-opus-4.1', 'General / Reasoning', '["Advanced reasoning", "Code generation"]', 'Claude Opus 4.1 is a drop-in replacement for Opus 4 that delivers superior performance and precision for real-world coding and agentic tasks. Opus 4.1 advances state-of-the-art coding performance to 74.5% on SWE-bench Verified, and handles complex, multi-step problems with more rigor and attention to detail.', '200K', '< 30 seconds'),
  ('openai-gpt-4o-mini', 'gpt-4o-mini', 'General / Reasoning', '["Multimodal", "Fast responses", "Cost-effective"]', 'GPT-4o mini from OpenAI is their most advanced and cost-efficient small model. It is multi-modal (accepting text or image inputs and outputting text) and has higher intelligence than gpt-3.5-turbo but is just as fast.', '128K', '< 30 seconds'),
  ('openai-gpt-oss-120b', 'gpt-oss-120b', 'General / Reasoning', '["Advanced reasoning"]', 'Extremely capable general-purpose LLM with strong, controllable reasoning capabilities', '131K', '< 30 seconds'),
  ('xai-grok-code-fast-1', 'grok-code-fast-1', 'Coding / Code-Assist', '["Code generation", "Fast responses"]', 'xAI''s latest coding model that offers fast agentic coding with a 256K context window.', '256K', '< 30 seconds'),
  ('stealth-sonoma-sky-alpha', 'sonoma-sky-alpha', 'General / Reasoning', '["Multimodal"]', 'A maximally intelligent general-purpose frontier model with a 2 million token context window. Supports image inputs and parallel tool calling. Note: prompts and responses may be retained and used for training by the provider during the stealth period.', '2M', '< 30 seconds'),
  ('anthropic-claude-3-5-sonnet', 'claude-3.5-sonnet', 'General / Reasoning', '["Fast responses", "Cost-effective"]', 'Claude 3.5 Sonnet strikes the ideal balance between intelligence and speedâ€”particularly for enterprise workloads. It delivers strong performance at a lower cost compared to its peers, and is engineered for high endurance in large-scale AI deployments.', '200K', '< 30 seconds'),
  ('google-gemini-2-0-flash-lite', 'gemini-2.0-flash-lite', 'General / Reasoning', '["Multimodal", "Fast responses"]', 'Gemini 2.0 Flash delivers next-gen features and improved capabilities, including superior speed, built-in tool use, multimodal generation, and a 1M token context window.', '1M', '< 10 seconds'),
  ('xai-grok-3-mini', 'grok-3-mini', 'General / Reasoning', '["General purpose"]', 'xAI''s lightweight model that thinks before responding. Great for simple or logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible.', '131K', '< 30 seconds'),
  ('xai-grok-4', 'grok-4', 'General / Reasoning', '["Advanced reasoning"]', 'xAI''s latest and greatest flagship model, offering unparalleled performance in natural language, math and reasoning - the perfect jack of all trades.', '256K', '< 30 seconds'),
  ('xai-grok-3', 'grok-3', 'General / Reasoning', '["Code generation"]', 'xAI''s flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.', '131K', '< 30 seconds'),
  ('perplexity-sonar', 'sonar', 'General / Reasoning', '["Fast responses"]', 'Perplexity''s lightweight offering with search grounding, quicker and cheaper than Sonar Pro.', '127K', '< 30 seconds'),
  ('anthropic-claude-3-5-haiku', 'claude-3.5-haiku', 'General / Reasoning', '["Fast responses"]', 'Claude 3.5 Haiku is the next generation of our fastest model. For a similar speed to Claude 3 Haiku, Claude 3.5 Haiku improves across every skill set and surpasses Claude 3 Opus, the largest model in our previous generation, on many intelligence benchmarks.', '200K', '< 30 seconds'),
  ('mistral-codestral-embed', 'codestral-embed', 'Embedding', '["Code generation"]', 'Code embedding model that can embed code databases and repositories to power coding assistants. Input Tokens $0.15/M mistral logo Available on 1 provider xai logo', '', 'Instant'),
  ('xai-grok-3-fast', 'grok-3-fast', 'General / Reasoning', '["Code generation", "Fast responses", "Cost-effective"]', 'xAI''s flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science. The fast model variant is served on faster infrastructure, offering response times that are significantly faster than the standard. The increased speed comes at a higher cost per output token.', '131K', '< 30 seconds'),
  ('deepseek-deepseek-v3', 'deepseek-v3', 'General / Reasoning', '["Advanced reasoning", "Fast responses"]', 'Fast general-purpose LLM with enhanced reasoning capabilities', '164K', '< 30 seconds'),
  ('zai-glm-4-5', 'glm-4.5', 'General / Reasoning', '["General purpose"]', 'GLM-4.5 and GLM-4.5-Air are our latest flagship models, purpose-built as foundational models for agent-oriented applications. Both leverage a Mixture-of-Experts (MoE) architecture. GLM-4.5 has a total parameter count of 355B with 32B active parameters per forward pass, while GLM-4.5-Air adopts a more streamlined design with 106B total parameters and 12B active parameters.', '128K', '< 30 seconds'),
  ('meta-llama-4-maverick', 'llama-4-maverick', 'General / Reasoning', '["General purpose"]', 'High-efficiency language processing', '1M', '< 30 seconds'),
  ('openai-gpt-3-5-turbo', 'gpt-3.5-turbo', 'General / Reasoning', '["Cost-effective"]', 'OpenAI''s most capable and cost effective model in the GPT-3.5 family optimized for chat purposes, but also works well for traditional completions tasks.', '16K', '< 30 seconds'),
  ('mistral-pixtral-12b', 'pixtral-12b', 'General / Reasoning', '["Multimodal"]', 'A 12B model with image understanding capabilities in addition to text.', '128K', '< 30 seconds'),
  ('openai-gpt-oss-20b', 'gpt-oss-20b', 'General / Reasoning', '["General purpose"]', 'A compact, open-weight language model optimized for low-latency and resource-constrained environments, including local and edge deployments', '128K', '< 30 seconds'),
  ('stealth-sonoma-dusk-alpha', 'sonoma-dusk-alpha', 'General / Reasoning', '["Multimodal", "Fast responses"]', 'A fast and intelligent general-purpose frontier model with a 2 million token context window. Supports image inputs and parallel tool calling. Note: prompts and responses may be retained and used for training by the provider during the stealth period.', '2M', '< 30 seconds'),
  ('meta-llama-4-scout', 'llama-4-scout', 'General / Reasoning', '["Multimodal", "Advanced reasoning", "Code generation"]', 'The Llama-4-Scout-17B-16E-Instruct model is a state-of-the-art, instruction-tuned, multimodal AI model developed by Meta as part of the Llama 4 family. It is designed to handle both text and image inputs, making it suitable for a wide range of applications, including conversational AI, code generation, and visual reasoning.', '128K', '< 30 seconds'),
  ('perplexity-sonar-pro', 'sonar-pro', 'General / Reasoning', '["General purpose"]', 'Perplexity''s premier offering with search grounding, supporting advanced queries and follow-ups.', '200K', '< 30 seconds'),
  ('xai-grok-2-vision', 'grok-2-vision', 'General / Reasoning', '["Advanced reasoning"]', 'Grok 2 vision model excels in vision-based tasks, delivering state-of-the-art performance in visual math reasoning (MathVista) and document-based question answering (DocVQA). It can process a wide variety of visual information including documents, diagrams, charts, screenshots, and photographs.', '33K', '< 30 seconds'),
  ('google-gemini-embedding-001', 'gemini-embedding-001', 'Embedding', '["Code generation"]', 'State-of-the-art embedding model with excellent performance across English, multilingual and code tasks. Input Tokens $0.15/M google logo vertex logo Available on 2 providers mistral logo', '', 'Instant'),
  ('mistral-mistral-small', 'mistral-small', 'General / Reasoning', '["General purpose"]', 'Mistral Small is the ideal choice for simple tasks that one can do in bulk - like Classification, Customer Support, or Text Generation. It offers excellent performance at an affordable price point.', '32K', '< 30 seconds'),
  ('mistral-codestral', 'codestral', 'Coding / Code-Assist', '["Code generation"]', 'Mistral Codestral 25.01 is a state-of-the-art coding model optimized for low-latency, high-frequency use cases. Proficient in over 80 programming languages, it excels at tasks like fill-in-the-middle (FIM), code correction, and test generation.', '256K', '< 30 seconds'),
  ('google-gemini-2-5-flash-image-preview', 'gemini-2.5-flash-image-preview', 'Image Gen / Multimodal', '["Multimodal", "Advanced reasoning", "Cost-effective"]', 'Image Generation Gemini 2.5 Flash Image Preview is our first fully hybrid reasoning model, letting developers turn thinking on or off and set thinking budgets to balance quality, cost, and latency. Upgraded for rapid creative workflows, it can generate interleaved text and images and supports conversational, multiâ€‘turn image editing in natural language. Itâ€™s also localeâ€‘aware, enabling culturally and linguistically appropriate image generation for audiences worldwide.', '1M', '< 10 seconds'),
  ('zai-glm-4-5-air', 'glm-4.5-air', 'General / Reasoning', '["General purpose"]', 'GLM-4.5 and GLM-4.5-Air are our latest flagship models, purpose-built as foundational models for agent-oriented applications. Both leverage a Mixture-of-Experts (MoE) architecture. GLM-4.5 has a total parameter count of 355B with 32B active parameters per forward pass, while GLM-4.5-Air adopts a more streamlined design with 106B total parameters and 12B active parameters.', '128K', '< 30 seconds'),
  ('alibaba-qwen-3-235b', 'qwen-3-235b', 'General / Reasoning', '["Advanced reasoning"]', 'Mixture-of-experts LLM with math and reasoning capabilities', '262K', '< 30 seconds'),
  ('openai-text-embedding-ada-002', 'text-embedding-ada-002', 'Embedding', '["General purpose"]', 'OpenAI''s legacy text embedding model. Input Tokens $0.10/M azure logo openai logo Available on 2 providers deepseek logo', '', 'Instant'),
  ('deepseek-deepseek-r1', 'deepseek-r1', 'General / Reasoning', '["Advanced reasoning"]', 'DeepSeek Reasoner is a specialized model developed by DeepSeek that uses Chain of Thought (CoT) reasoning to improve response accuracy. Before providing a final answer, it generates detailed reasoning steps that are accessible through the API, allowing users to examine and leverage the model''s thought process, served by Fireworks AI.', '160K', '< 30 seconds'),
  ('anthropic-claude-3-haiku', 'claude-3-haiku', 'General / Reasoning', '["Fast responses", "Cost-effective"]', 'Claude 3 Haiku is Anthropic''s fastest model yet, designed for enterprise workloads which often involve longer prompts. Haiku to quickly analyze large volumes of documents, such as quarterly filings, contracts, or legal cases, for half the cost of other models in its performance tier.', '200K', '< 30 seconds'),
  ('openai-o4-mini', 'o4-mini', 'General / Reasoning', '["Advanced reasoning", "Code generation", "Fast responses", "Cost-effective"]', 'OpenAI''s o4-mini delivers fast, cost-efficient reasoning with exceptional performance for its size, particularly excelling in math (best-performing on AIME benchmarks), coding, and visual tasks.', '200K', '< 30 seconds'),
  ('openai-text-embedding-3-large', 'text-embedding-3-large', 'Embedding', '["General purpose"]', 'OpenAI''s most capable embedding model for both english and non-english tasks. Input Tokens $0.13/M azure logo openai logo Available on 2 providers openai logo', '', 'Instant'),
  ('openai-o3', 'o3', 'General / Reasoning', '["Multimodal", "Advanced reasoning", "Code generation"]', 'OpenAI''s o3 is their most powerful reasoning model, setting new state-of-the-art benchmarks in coding, math, science, and visual perception. It excels at complex queries requiring multi-faceted analysis, with particular strength in analyzing images, charts, and graphics.', '200K', '< 30 seconds'),
  ('alibaba-qwen3-max', 'qwen3-max', 'General / Reasoning', '["General purpose"]', 'Qwen3-Max improves instruction following, multilingual ability, and tool use; reduced hallucinations.', '262K', '< 30 seconds'),
  ('anthropic-claude-opus-4', 'claude-opus-4', 'General / Reasoning', '["Code generation"]', 'Claude Opus 4 is Anthropic''s most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hoursâ€”dramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.', '200K', '< 30 seconds'),
  ('openai-o3-mini', 'o3-mini', 'General / Reasoning', '["Advanced reasoning", "Cost-effective"]', 'o3-mini is OpenAI''s most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini.', '200K', '< 30 seconds'),
  ('xai-grok-2', 'grok-2', 'General / Reasoning', '["Advanced reasoning", "Code generation"]', 'Grok 2 is a frontier language model with state-of-the-art reasoning capabilities. It features advanced capabilities in chat, coding, and reasoning, outperforming both Claude 3.5 Sonnet and GPT-4-Turbo on the LMSYS leaderboard.', '131K', '< 30 seconds'),
  ('vercel-v0-1-5-md', 'v0-1.5-md', 'General / Reasoning', '["Advanced reasoning"]', 'Access the model behind v0 to generate, fix, and optimize modern web apps with framework-specific reasoning and up-to-date knowledge.', '128K', '< 30 seconds'),
  ('anthropic-claude-3-opus', 'claude-3-opus', 'General / Reasoning', '["Advanced reasoning"]', 'Claude 3 Opus is Anthropic''s most intelligent model, with best-in-market performance on highly complex tasks. It can navigate open-ended prompts and sight-unseen scenarios with remarkable fluency and human-like understanding. Opus shows us the outer limits of what''s possible with generative AI.', '200K', '< 30 seconds'),
  ('openai-gpt-4o', 'gpt-4o', 'General / Reasoning', '["Advanced reasoning", "Fast responses"]', 'GPT-4o from OpenAI has broad general knowledge and domain expertise allowing it to follow complex instructions in natural language and solve difficult problems accurately. It matches GPT-4 Turbo performance with a faster and cheaper API.', '128K', '< 30 seconds'),
  ('amazon-nova-pro', 'nova-pro', 'General / Reasoning', '["Multimodal", "Fast responses", "Cost-effective"]', 'A highly capable multimodal model with the best combination of accuracy, speed, and cost for a wide range of tasks.', '300K', '< 30 seconds'),
  ('moonshotai-kimi-k2-turbo', 'kimi-k2-turbo', 'General / Reasoning', '["Fast responses"]', 'Kimi K2 Turbo is the high-speed version of kimi-k2, with the same model parameters as kimi-k2, but the output speed is increased to 60 tokens per second, with a maximum of 100 tokens per second, the context length is 256k', '256K', '< 30 seconds'),
  ('meituan-longcat-flash-chat', 'longcat-flash-chat', 'General / Reasoning', '["General purpose"]', 'LongCat-Flash-Chat is a high-throughput MoE chat model (128k context) optimized for agentic tasks.', '128K', '< 10 seconds'),
  ('meta-llama-3-3-70b', 'llama-3.3-70b', 'General / Reasoning', '["Advanced reasoning", "Code generation"]', 'The upgraded Llama 3.1 70B model features enhanced reasoning, tool use, and multilingual abilities, along with a significantly expanded 128K context window. These improvements make it well-suited for demanding tasks such as long-form summarization, multilingual conversations, and coding assistance.', '128K', '< 30 seconds'),
  ('meta-llama-3-1-8b', 'llama-3.1-8b', 'General / Reasoning', '["Code generation", "Cost-effective"]', 'Llama 3.1 8B brings powerful performance in a smaller, more efficient package. With improved multilingual support, tool use, and a 128K context length, it enables sophisticated use cases like interactive agents and compact coding assistants while remaining lightweight and accessible.', '128K', '< 30 seconds'),
  ('vercel-v0-1-0-md', 'v0-1.0-md', 'General / Reasoning', '["Advanced reasoning"]', 'Access the model behind v0 to generate, fix, and optimize modern web apps with framework-specific reasoning and up-to-date knowledge.', '128K', '< 30 seconds'),
  ('alibaba-qwen-3-14b', 'qwen-3-14b', 'General / Reasoning', '["Advanced reasoning"]', 'Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support', '41K', '< 30 seconds'),
  ('deepseek-deepseek-v3-1-thinking', 'deepseek-v3.1-thinking', 'General / Reasoning', '["Advanced reasoning", "Fast responses", "Cost-effective"]', 'DeepSeek-V3.1 marks DeepSeek''s first step toward the agent era with revolutionary hybrid inference capabilities. Operates in two modes: Think and Non-Think. The Think variant delivers faster reasoning compared to DeepSeek-R1-0528, reaching answers more efficiently while maintaining high-quality outputs. Enhanced through specialized post-training, the model excels at tool usage and complex multi-step agent tasks.', '128K', '< 30 seconds'),
  ('xai-grok-3-mini-fast', 'grok-3-mini-fast', 'General / Reasoning', '["Fast responses", "Cost-effective"]', 'xAI''s lightweight model that thinks before responding. Great for simple or logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible. The fast model variant is served on faster infrastructure, offering response times that are significantly faster than the standard. The increased speed comes at a higher cost per output token.', '131K', '< 30 seconds'),
  ('morph-morph-v3-large', 'morph-v3-large', 'Coding / Code-Assist', '["Code generation", "Fast responses"]', 'Morph offers a specialized AI model that applies code changes suggested by frontier models (like Claude or GPT-4o) to your existing code files FAST - 2500+ tokens/second. It acts as the final step in the AI coding workflow. Supports 16k input tokens and 16k output tokens.', '82K', '< 30 seconds'),
  ('alibaba-qwen-3-30b', 'qwen-3-30b', 'General / Reasoning', '["Advanced reasoning"]', 'Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support', '41K', '< 30 seconds'),
  ('google-gemma-2-9b', 'gemma-2-9b', 'General / Reasoning', '["Fast responses", "Cost-effective"]', '9 billion parameter open source model by Google fine-tuned for chat purposes. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.', '8K', '< 30 seconds'),
  ('morph-morph-v3-fast', 'morph-v3-fast', 'Coding / Code-Assist', '["Code generation", "Fast responses"]', 'Morph offers a specialized AI model that applies code changes suggested by frontier models (like Claude or GPT-4o) to your existing code files FAST - 4500+ tokens/second. It acts as the final step in the AI coding workflow. Supports 16k input tokens and 16k output tokens.', '82K', '< 30 seconds'),
  ('amazon-nova-micro', 'nova-micro', 'General / Reasoning', '["Cost-effective"]', 'A text-only model that delivers the lowest latency responses at very low cost.', '128K', '< 30 seconds'),
  ('openai-gpt-4-turbo', 'gpt-4-turbo', 'General / Reasoning', '["Advanced reasoning"]', 'gpt-4-turbo from OpenAI has broad general knowledge and domain expertise allowing it to follow complex instructions in natural language and solve difficult problems accurately. It has a knowledge cutoff of April 2023 and a 128,000 token context window.', '128K', '< 30 seconds'),
  ('mistral-mistral-embed', 'mistral-embed', 'Embedding', '["General purpose"]', 'General-purpose text embedding model for semantic search, similarity, clustering, and RAG workflows. Input Tokens $0.10/M mistral logo Available on 1 provider amazon logo', '', 'Instant'),
  ('amazon-titan-embed-text-v2', 'titan-embed-text-v2', 'Embedding', '["Cost-effective"]', 'Amazon Titan Text Embeddings V2 is a light weight, efficient multilingual embedding model supporting 1024, 512, and 256 dimensions. Input Tokens $0.02/M bedrock logo Available on 1 provider deepseek logo', '', 'Instant'),
  ('deepseek-deepseek-r1-distill-llama-70b', 'deepseek-r1-distill-llama-70b', 'General / Reasoning', '["Advanced reasoning", "Code generation"]', 'DeepSeek-R1 is a state-of-the-art reasoning model trained with reinforcement learning and cold-start data, delivering strong performance across math, code, and complex reasoning tasks. It offers improved stability, readability, and multilingual handling compared to earlier versions, and is available alongside several high-quality distilled variants.', '128K', '< 30 seconds'),
  ('mistral-ministral-3b', 'ministral-3b', 'General / Reasoning', '["Cost-effective"]', 'A compact, efficient model for on-device tasks like smart assistants and local analytics, offering low-latency performance.', '128K', '< 30 seconds'),
  ('alibaba-qwen-3-32b', 'qwen-3-32b', 'General / Reasoning', '["Advanced reasoning", "Code generation"]', 'Qwen3-32B is a world-class model with comparable quality to DeepSeek R1 while outperforming GPT-4.1 and Claude Sonnet 3.7. It excels in code-gen, tool-calling, and advanced reasoning, making it an exceptional model for a wide range of production use cases.', '128K', '< 30 seconds'),
  ('mistral-mistral-large', 'mistral-large', 'General / Reasoning', '["Advanced reasoning", "Code generation"]', 'Mistral Large is ideal for complex tasks that require large reasoning capabilities or are highly specialized - like Synthetic Text Generation, Code Generation, RAG, or Agents.', '32K', '< 30 seconds'),
  ('mistral-magistral-small', 'magistral-small', 'General / Reasoning', '["Advanced reasoning"]', 'Complex thinking, backed by deep understanding, with transparent reasoning you can follow and verify. The model excels in maintaining high-fidelity reasoning across numerous languages, even when switching between languages mid-task.', '128K', '< 30 seconds'),
  ('cohere-command-a', 'command-a', 'General / Reasoning', '["General purpose"]', 'Command A is Cohere''s most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. Command A has a context length of 256K, only requires two GPUs to run, and has 150% higher throughput compared to Command R+ 08-2024.', '256K', '< 30 seconds'),
  ('deepseek-deepseek-v3-1-base', 'deepseek-v3.1-base', 'General / Reasoning', '["General purpose"]', 'DeepSeek V3.1 Base is an improved version of the DeepSeek V3 model.', '128K', '< 30 seconds'),
  ('amazon-nova-lite', 'nova-lite', 'General / Reasoning', '["Multimodal", "Fast responses", "Cost-effective"]', 'A very low cost multimodal model that is lightning fast for processing image, video, and text inputs.', '300K', '< 10 seconds'),
  ('zai-glm-4-5v', 'glm-4.5v', 'General / Reasoning', '["General purpose"]', 'Built on the GLM-4.5-Air base model, GLM-4.5V inherits proven techniques from GLM-4.1V-Thinking while achieving effective scaling through a powerful 106B-parameter MoE architecture.', '66K', '< 30 seconds'),
  ('perplexity-sonar-reasoning', 'sonar-reasoning', 'General / Reasoning', '["Advanced reasoning"]', 'A reasoning-focused model that outputs Chain of Thought (CoT) in responses, providing detailed explanations with search grounding.', '127K', '< 30 seconds'),
  ('meta-llama-3-2-1b', 'llama-3.2-1b', 'General / Reasoning', '["General purpose"]', 'Text-only model, supporting on-device use cases such as multilingual local knowledge retrieval, summarization, and rewriting.', '128K', '< 30 seconds'),
  ('mistral-pixtral-large', 'pixtral-large', 'General / Reasoning', '["Multimodal"]', 'Pixtral Large is the second model in our multimodal family and demonstrates frontier-level image understanding. Particularly, the model is able to understand documents, charts and natural images, while maintaining the leading text-only understanding of Mistral Large 2.', '128K', '< 30 seconds'),
  ('perplexity-sonar-reasoning-pro', 'sonar-reasoning-pro', 'General / Reasoning', '["Advanced reasoning"]', 'A premium reasoning-focused model that outputs Chain of Thought (CoT) in responses, providing comprehensive explanations with enhanced search capabilities and multiple search queries per request.', '127K', '< 30 seconds'),
  ('mistral-mixtral-8x22b-instruct', 'mixtral-8x22b-instruct', 'General / Reasoning', '["General purpose"]', '8x22b Instruct model. 8x22b is mixture-of-experts open source model by Mistral served by Fireworks.', '66K', '< 30 seconds'),
  ('meta-llama-3-2-3b', 'llama-3.2-3b', 'General / Reasoning', '["General purpose"]', 'Text-only model, fine-tuned for supporting on-device use cases such as multilingual local knowledge retrieval, summarization, and rewriting.', '128K', '< 30 seconds'),
  ('mistral-devstral-small', 'devstral-small', 'Coding / Code-Assist', '["Code generation"]', 'Devstral is an agentic LLM for software engineering tasks built under a collaboration between Mistral AI and All Hands AI ðŸ™Œ. Devstral excels at using tools to explore codebases, editing multiple files and power software engineering agents.', '128K', '< 30 seconds'),
  ('mistral-mistral-medium', 'mistral-medium', 'General / Reasoning', '["Cost-effective"]', 'Mistral Medium 3 delivers frontier performance while being an order of magnitude less expensive. For instance, the model performs at or above 90% of Claude Sonnet 3.7 on benchmarks across the board at a significantly lower cost.', '128K', '< 30 seconds'),
  ('openai-o1', 'o1', 'General / Reasoning', '["Advanced reasoning"]', 'o1 is OpenAI''s flagship reasoning model, designed for complex problems that require deep thinking. It provides strong reasoning capabilities with improved accuracy for complex multi-step tasks.', '200K', '< 30 seconds'),
  ('mistral-ministral-8b', 'ministral-8b', 'General / Reasoning', '["Advanced reasoning", "Fast responses", "Cost-effective"]', 'A more powerful model with faster, memory-efficient inference, ideal for complex workflows and demanding edge applications.', '128K', '< 30 seconds'),
  ('meta-llama-3-2-90b', 'llama-3.2-90b', 'General / Reasoning', '["Multimodal", "Advanced reasoning"]', 'Instruction-tuned image reasoning generative model (text + images in / text out) optimized for visual recognition, image reasoning, captioning and answering general questions about the image.', '128K', '< 30 seconds'),
  ('meta-llama-3-1-70b', 'llama-3.1-70b', 'General / Reasoning', '["Advanced reasoning"]', 'An update to Meta Llama 3 70B Instruct that includes an expanded 128K context length, multilinguality and improved reasoning capabilities.', '128K', '< 30 seconds'),
  ('inception-mercury-coder-small', 'mercury-coder-small', 'Coding / Code-Assist', '["Code generation"]', 'Mercury Coder Small is ideal for code generation, debugging, and refactoring tasks with minimal latency.', '32K', '< 30 seconds'),
  ('google-text-embedding-005', 'text-embedding-005', 'Embedding', '["Code generation"]', 'English-focused text embedding model optimized for code and English language tasks. Input Tokens $0.03/M vertex logo Available on 1 provider cohere logo', '', 'Instant'),
  ('cohere-command-r', 'command-r', 'General / Reasoning', '["General purpose"]', 'Command R is a large language model optimized for conversational interaction and long context tasks. It targets the scalable category of models that balance high performance with strong accuracy, enabling companies to move beyond proof of concept and into production.', '128K', '< 30 seconds'),
  ('mistral-magistral-medium', 'magistral-medium', 'General / Reasoning', '["Advanced reasoning"]', 'Complex thinking, backed by deep understanding, with transparent reasoning you can follow and verify. The model excels in maintaining high-fidelity reasoning across numerous languages, even when switching between languages mid-task.', '128K', '< 30 seconds'),
  ('cohere-embed-v4-0', 'embed-v4.0', 'Embedding', '["Multimodal"]', 'A model that allows for text, images, or mixed content to be classified or turned into embeddings. Input Tokens $0.12/M cohere logo Available on 1 provider meta logo', '', 'Instant'),
  ('meta-llama-3-2-11b', 'llama-3.2-11b', 'General / Reasoning', '["Multimodal", "Advanced reasoning"]', 'Instruction-tuned image reasoning generative model (text + images in / text out) optimized for visual recognition, image reasoning, captioning and answering general questions about the image.', '128K', '< 30 seconds'),
  ('cohere-command-r-plus', 'command-r-plus', 'General / Reasoning', '["General purpose"]', 'Command R+ is Cohere''s newest large language model, optimized for conversational interaction and long-context tasks. It aims at being extremely performant, enabling companies to move beyond proof of concept and into production.', '128K', '< 30 seconds'),
  ('voyage-voyage-3-5-lite', 'voyage-3.5-lite', 'Embedding', '["Cost-effective"]', 'Voyage AI''s embedding model optimized for latency and cost. Input Tokens $0.02/M voyage logo Available on 1 provider voyage logo', '', '< 10 seconds'),
  ('voyage-voyage-code-2', 'voyage-code-2', 'Embedding', '["Code generation"]', 'Voyage AI''s embedding model optimized for code retrieval (17% better than alternatives). This is the previous generation of code embeddings models. Input Tokens $0.12/M voyage logo Available on 1 provider voyage logo', '', 'Instant'),
  ('voyage-voyage-law-2', 'voyage-law-2', 'Embedding', '["General purpose"]', 'Voyage AI''s embedding model optimized for legal retrieval and RAG. Input Tokens $0.12/M voyage logo Available on 1 provider voyage logo', '', 'Instant'),
  ('voyage-voyage-finance-2', 'voyage-finance-2', 'Embedding', '["General purpose"]', 'Voyage AI''s embedding model optimized for finance retrieval and RAG. Input Tokens $0.12/M voyage logo Available on 1 provider google logo', '', 'Instant'),
  ('google-text-multilingual-embedding-002', 'text-multilingual-embedding-002', 'Embedding', '["General purpose"]', 'Multilingual text embedding model optimized for cross-lingual tasks across many languages. Input Tokens $0.03/M vertex logo Available on 1 provider voyage logo', '', 'Instant'),
  ('voyage-voyage-3-5', 'voyage-3.5', 'Embedding', '["General purpose"]', 'Voyage AI''s embedding model optimized for general-purpose and multilingual retrieval quality. Input Tokens $0.06/M voyage logo Available on 1 provider voyage logo', '', 'Instant'),
  ('voyage-voyage-code-3', 'voyage-code-3', 'Embedding', '["Code generation"]', 'Voyage AI''s embedding model optimized for code retrieval. Input Tokens $0.18/M voyage logo Available on 1 provider voyage logo', '', 'Instant'),
  ('voyage-voyage-3-large', 'voyage-3-large', 'Embedding', '["General purpose"]', 'Voyage AI''s embedding model with the best general-purpose and multilingual retrieval quality. Input Tokens $0.18/M voyage logo Available on 1 provider meta logo', '', 'Instant'),
  ('meta-llama-3-8b', 'llama-3-8b', 'General / Reasoning', '["Fast responses", "Cost-effective"]', 'Llama is a 8 billion parameter open source model by Meta fine-tuned for instruction following purposes. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.', '8K', '< 30 seconds'),
  ('openai-gpt-3-5-turbo-instruct', 'gpt-3.5-turbo-instruct', 'General / Reasoning', '["General purpose"]', 'Similar capabilities as GPT-3 era models. Compatible with legacy Completions endpoint and not Chat Completions.', '8K', '< 30 seconds'),
  ('meta-llama-3-70b', 'llama-3-70b', 'General / Reasoning', '["Fast responses", "Cost-effective"]', 'Llama is a 70 billion parameter open source model by Meta fine-tuned for instruction following purposes. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.', '8K', '< 30 seconds');

-- Insert model-provider relationships
INSERT OR IGNORE INTO model_providers (model_id, provider, pricing, priority, is_active) VALUES
  ('anthropic-claude-sonnet-4', 'anthropic', '{"inputTokens": "3.0", "outputTokens": "15.0", "cacheRead": "0.3", "cacheWrite": "3.75"}', 1, 1),
  ('openai-gpt-5', 'openai', '{"inputTokens": "1.25", "outputTokens": "10.0", "cacheRead": "0.13", "cacheWrite": ""}', 1, 1),
  ('google-gemini-2-0-flash', 'google', '{"inputTokens": "0.15", "outputTokens": "0.6", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-4-1-nano', 'openai', '{"inputTokens": "0.1", "outputTokens": "0.4", "cacheRead": "0.03", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-5-mini', 'openai', '{"inputTokens": "0.25", "outputTokens": "2.0", "cacheRead": "0.03", "cacheWrite": ""}', 1, 1),
  ('google-gemini-2-5-pro', 'google', '{"inputTokens": "2.5", "outputTokens": "10.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('google-gemini-2-5-flash', 'google', '{"inputTokens": "0.3", "outputTokens": "2.5", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('google-gemini-2-5-flash-lite', 'google', '{"inputTokens": "0.1", "outputTokens": "0.4", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-4-1', 'openai', '{"inputTokens": "2.0", "outputTokens": "8.0", "cacheRead": "0.5", "cacheWrite": ""}', 1, 1),
  ('openai-text-embedding-3-small', 'openai', '{"inputTokens": "0.02", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-4-1-mini', 'openai', '{"inputTokens": "0.4", "outputTokens": "1.6", "cacheRead": "0.1", "cacheWrite": ""}', 1, 1),
  ('anthropic-claude-3-7-sonnet', 'anthropic', '{"inputTokens": "3.0", "outputTokens": "15.0", "cacheRead": "0.3", "cacheWrite": "3.75"}', 1, 1),
  ('openai-gpt-5-nano', 'openai', '{"inputTokens": "0.05", "outputTokens": "0.4", "cacheRead": "0.01", "cacheWrite": ""}', 1, 1),
  ('deepseek-deepseek-v3-1', 'deepseek', '{"inputTokens": "0.2", "outputTokens": "0.8", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-4o', 'openai', '{"inputTokens": "2.5", "outputTokens": "10.0", "cacheRead": "1.25", "cacheWrite": ""}', 1, 1),
  ('moonshotai-kimi-k2-0905', 'moonshotai', '{"inputTokens": "0.6", "outputTokens": "1.2", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('moonshotai-kimi-k2', 'moonshotai', '{"inputTokens": "0.5", "outputTokens": "2.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('alibaba-qwen3-coder', 'alibaba', '{"inputTokens": "0.4", "outputTokens": "1.6", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('anthropic-claude-opus-4-1', 'anthropic', '{"inputTokens": "15.0", "outputTokens": "75.0", "cacheRead": "1.5", "cacheWrite": "18.75"}', 1, 1),
  ('openai-gpt-4o-mini', 'openai', '{"inputTokens": "0.15", "outputTokens": "0.6", "cacheRead": "0.07", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-oss-120b', 'openai', '{"inputTokens": "0.1", "outputTokens": "0.5", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('xai-grok-code-fast-1', 'xai', '{"inputTokens": "0.2", "outputTokens": "1.5", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('stealth-sonoma-sky-alpha', 'stealth', '{"inputTokens": "0.0", "outputTokens": "0.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('anthropic-claude-3-5-sonnet', 'anthropic', '{"inputTokens": "3.0", "outputTokens": "15.0", "cacheRead": "0.3", "cacheWrite": "3.75"}', 1, 1),
  ('google-gemini-2-0-flash-lite', 'google', '{"inputTokens": "0.07", "outputTokens": "0.3", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('xai-grok-3-mini', 'xai', '{"inputTokens": "0.3", "outputTokens": "0.5", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('xai-grok-4', 'xai', '{"inputTokens": "3.0", "outputTokens": "15.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('xai-grok-3', 'xai', '{"inputTokens": "3.0", "outputTokens": "15.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('perplexity-sonar', 'perplexity', '{"inputTokens": "1.0", "outputTokens": "1.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('anthropic-claude-3-5-haiku', 'anthropic', '{"inputTokens": "0.8", "outputTokens": "4.0", "cacheRead": "0.08", "cacheWrite": "1.0"}', 1, 1),
  ('mistral-codestral-embed', 'mistral', '{"inputTokens": "0.15", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('xai-grok-3-fast', 'xai', '{"inputTokens": "5.0", "outputTokens": "25.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('deepseek-deepseek-v3', 'deepseek', '{"inputTokens": "0.77", "outputTokens": "0.77", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('zai-glm-4-5', 'zai', '{"inputTokens": "0.6", "outputTokens": "2.2", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-4-maverick', 'meta', '{"inputTokens": "0.15", "outputTokens": "0.6", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-3-5-turbo', 'openai', '{"inputTokens": "0.5", "outputTokens": "1.5", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-pixtral-12b', 'mistral', '{"inputTokens": "0.15", "outputTokens": "0.15", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-oss-20b', 'openai', '{"inputTokens": "0.07", "outputTokens": "0.3", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('stealth-sonoma-dusk-alpha', 'stealth', '{"inputTokens": "0.0", "outputTokens": "0.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-4-scout', 'meta', '{"inputTokens": "0.08", "outputTokens": "0.3", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('perplexity-sonar-pro', 'perplexity', '{"inputTokens": "3.0", "outputTokens": "15.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('xai-grok-2-vision', 'xai', '{"inputTokens": "2.0", "outputTokens": "10.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('google-gemini-embedding-001', 'google', '{"inputTokens": "0.15", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-mistral-small', 'mistral', '{"inputTokens": "0.1", "outputTokens": "0.3", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-codestral', 'mistral', '{"inputTokens": "0.3", "outputTokens": "0.9", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('google-gemini-2-5-flash-image-preview', 'google', '{"inputTokens": "0.3", "outputTokens": "2.5", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('zai-glm-4-5-air', 'zai', '{"inputTokens": "0.2", "outputTokens": "1.1", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('alibaba-qwen-3-235b', 'alibaba', '{"inputTokens": "0.13", "outputTokens": "0.6", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-text-embedding-ada-002', 'openai', '{"inputTokens": "0.1", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('deepseek-deepseek-r1', 'deepseek', '{"inputTokens": "0.79", "outputTokens": "4.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('anthropic-claude-3-haiku', 'anthropic', '{"inputTokens": "0.25", "outputTokens": "1.25", "cacheRead": "0.03", "cacheWrite": "0.3"}', 1, 1),
  ('openai-o4-mini', 'openai', '{"inputTokens": "1.1", "outputTokens": "4.4", "cacheRead": "0.28", "cacheWrite": ""}', 1, 1),
  ('openai-text-embedding-3-large', 'openai', '{"inputTokens": "0.13", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-o3', 'openai', '{"inputTokens": "2.0", "outputTokens": "8.0", "cacheRead": "0.5", "cacheWrite": ""}', 1, 1),
  ('alibaba-qwen3-max', 'alibaba', '{"inputTokens": "1.2", "outputTokens": "6.0", "cacheRead": "0.24", "cacheWrite": ""}', 1, 1),
  ('anthropic-claude-opus-4', 'anthropic', '{"inputTokens": "15.0", "outputTokens": "75.0", "cacheRead": "1.5", "cacheWrite": "18.75"}', 1, 1),
  ('openai-o3-mini', 'openai', '{"inputTokens": "1.1", "outputTokens": "4.4", "cacheRead": "0.55", "cacheWrite": ""}', 1, 1),
  ('xai-grok-2', 'xai', '{"inputTokens": "2.0", "outputTokens": "10.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('vercel-v0-1-5-md', 'vercel', '{"inputTokens": "3.0", "outputTokens": "15.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('anthropic-claude-3-opus', 'anthropic', '{"inputTokens": "15.0", "outputTokens": "75.0", "cacheRead": "1.5", "cacheWrite": "18.75"}', 1, 1),
  ('openai-gpt-4o', 'openai', '{"inputTokens": "2.5", "outputTokens": "10.0", "cacheRead": "1.25", "cacheWrite": ""}', 1, 1),
  ('amazon-nova-pro', 'amazon', '{"inputTokens": "0.8", "outputTokens": "3.2", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('moonshotai-kimi-k2-turbo', 'moonshotai', '{"inputTokens": "2.4", "outputTokens": "10.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meituan-longcat-flash-chat', 'meituan', '{"inputTokens": "0.0", "outputTokens": "0.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-3-3-70b', 'meta', '{"inputTokens": "0.72", "outputTokens": "0.72", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-3-1-8b', 'meta', '{"inputTokens": "0.05", "outputTokens": "0.08", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('vercel-v0-1-0-md', 'vercel', '{"inputTokens": "3.0", "outputTokens": "15.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('alibaba-qwen-3-14b', 'alibaba', '{"inputTokens": "0.06", "outputTokens": "0.24", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('deepseek-deepseek-v3-1-thinking', 'deepseek', '{"inputTokens": "0.56", "outputTokens": "1.68", "cacheRead": "0.07", "cacheWrite": ""}', 1, 1),
  ('xai-grok-3-mini-fast', 'xai', '{"inputTokens": "0.6", "outputTokens": "4.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('morph-morph-v3-large', 'morph', '{"inputTokens": "0.9", "outputTokens": "1.9", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('alibaba-qwen-3-30b', 'alibaba', '{"inputTokens": "0.08", "outputTokens": "0.29", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('google-gemma-2-9b', 'google', '{"inputTokens": "0.2", "outputTokens": "0.2", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('morph-morph-v3-fast', 'morph', '{"inputTokens": "0.8", "outputTokens": "1.2", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('amazon-nova-micro', 'amazon', '{"inputTokens": "0.04", "outputTokens": "0.14", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-4-turbo', 'openai', '{"inputTokens": "10.0", "outputTokens": "30.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-mistral-embed', 'mistral', '{"inputTokens": "0.1", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('amazon-titan-embed-text-v2', 'amazon', '{"inputTokens": "0.02", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('deepseek-deepseek-r1-distill-llama-70b', 'deepseek', '{"inputTokens": "0.75", "outputTokens": "0.99", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-ministral-3b', 'mistral', '{"inputTokens": "0.04", "outputTokens": "0.04", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('alibaba-qwen-3-32b', 'alibaba', '{"inputTokens": "0.1", "outputTokens": "0.3", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-mistral-large', 'mistral', '{"inputTokens": "2.0", "outputTokens": "6.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-magistral-small', 'mistral', '{"inputTokens": "0.5", "outputTokens": "1.5", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('cohere-command-a', 'cohere', '{"inputTokens": "2.5", "outputTokens": "10.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('deepseek-deepseek-v3-1-base', 'deepseek', '{"inputTokens": "0.2", "outputTokens": "0.8", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('amazon-nova-lite', 'amazon', '{"inputTokens": "0.06", "outputTokens": "0.24", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('zai-glm-4-5v', 'zai', '{"inputTokens": "0.6", "outputTokens": "1.8", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('perplexity-sonar-reasoning', 'perplexity', '{"inputTokens": "1.0", "outputTokens": "5.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-3-2-1b', 'meta', '{"inputTokens": "0.1", "outputTokens": "0.1", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-pixtral-large', 'mistral', '{"inputTokens": "2.0", "outputTokens": "6.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('perplexity-sonar-reasoning-pro', 'perplexity', '{"inputTokens": "2.0", "outputTokens": "8.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-mixtral-8x22b-instruct', 'mistral', '{"inputTokens": "1.2", "outputTokens": "1.2", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-3-2-3b', 'meta', '{"inputTokens": "0.15", "outputTokens": "0.15", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-devstral-small', 'mistral', '{"inputTokens": "0.1", "outputTokens": "0.3", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-mistral-medium', 'mistral', '{"inputTokens": "0.4", "outputTokens": "2.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-o1', 'openai', '{"inputTokens": "15.0", "outputTokens": "60.0", "cacheRead": "7.5", "cacheWrite": ""}', 1, 1),
  ('mistral-ministral-8b', 'mistral', '{"inputTokens": "0.1", "outputTokens": "0.1", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-3-2-90b', 'meta', '{"inputTokens": "0.72", "outputTokens": "0.72", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-3-1-70b', 'meta', '{"inputTokens": "0.72", "outputTokens": "0.72", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('inception-mercury-coder-small', 'inception', '{"inputTokens": "0.25", "outputTokens": "1.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('google-text-embedding-005', 'google', '{"inputTokens": "0.03", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('cohere-command-r', 'cohere', '{"inputTokens": "0.15", "outputTokens": "0.6", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('mistral-magistral-medium', 'mistral', '{"inputTokens": "2.0", "outputTokens": "5.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('cohere-embed-v4-0', 'cohere', '{"inputTokens": "0.12", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-3-2-11b', 'meta', '{"inputTokens": "0.16", "outputTokens": "0.16", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('cohere-command-r-plus', 'cohere', '{"inputTokens": "2.5", "outputTokens": "10.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('voyage-voyage-3-5-lite', 'voyage', '{"inputTokens": "0.02", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('voyage-voyage-code-2', 'voyage', '{"inputTokens": "0.12", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('voyage-voyage-law-2', 'voyage', '{"inputTokens": "0.12", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('voyage-voyage-finance-2', 'voyage', '{"inputTokens": "0.12", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('google-text-multilingual-embedding-002', 'google', '{"inputTokens": "0.03", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('voyage-voyage-3-5', 'voyage', '{"inputTokens": "0.06", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('voyage-voyage-code-3', 'voyage', '{"inputTokens": "0.18", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('voyage-voyage-3-large', 'voyage', '{"inputTokens": "0.18", "outputTokens": "", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-3-8b', 'meta', '{"inputTokens": "0.05", "outputTokens": "0.08", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('openai-gpt-3-5-turbo-instruct', 'openai', '{"inputTokens": "1.5", "outputTokens": "2.0", "cacheRead": "", "cacheWrite": ""}', 1, 1),
  ('meta-llama-3-70b', 'meta', '{"inputTokens": "0.59", "outputTokens": "0.79", "cacheRead": "", "cacheWrite": ""}', 1, 1);

-- ============================================================================
-- MODEL CATEGORIZATION ASSIGNMENTS
-- ============================================================================

-- Cost tier assignments
INSERT OR IGNORE INTO model_cost_tier_assignments (model_id, cost_tier_id) VALUES
('anthropic-claude-sonnet-4', 'premium'),
('openai-gpt-5', 'premium'),
('google-gemini-2-0-flash', 'low_cost'),
('openai-gpt-4-1-nano', 'low_cost'),
('openai-gpt-5-mini', 'mid_range'),
('google-gemini-2-5-pro', 'premium'),
('google-gemini-2-5-flash', 'mid_range'),
('google-gemini-2-5-flash-lite', 'low_cost'),
('openai-gpt-4-1', 'premium'),
('openai-text-embedding-3-small', 'low_cost'),
('openai-gpt-4-1-mini', 'mid_range'),
('anthropic-claude-3-7-sonnet', 'premium'),
('openai-gpt-5-nano', 'low_cost'),
('deepseek-deepseek-v3-1', 'mid_range'),
('openai-gpt-4o', 'premium'),
('moonshotai-kimi-k2-0905', 'mid_range'),
('moonshotai-kimi-k2', 'mid_range'),
('alibaba-qwen3-coder', 'mid_range'),
('anthropic-claude-opus-4-1', 'premium'),
('openai-gpt-4o-mini', 'low_cost'),
('openai-gpt-oss-120b', 'low_cost'),
('xai-grok-code-fast-1', 'mid_range'),
('stealth-sonoma-sky-alpha', 'low_cost'),
('anthropic-claude-3-5-sonnet', 'premium'),
('google-gemini-2-0-flash-lite', 'low_cost'),
('xai-grok-3-mini', 'low_cost'),
('xai-grok-4', 'premium'),
('xai-grok-3', 'premium'),
('perplexity-sonar', 'mid_range'),
('anthropic-claude-3-5-haiku', 'premium'),
('mistral-codestral-embed', 'low_cost'),
('xai-grok-3-fast', 'premium'),
('deepseek-deepseek-v3', 'mid_range'),
('zai-glm-4-5', 'mid_range'),
('meta-llama-4-maverick', 'low_cost'),
('openai-gpt-3-5-turbo', 'mid_range'),
('mistral-pixtral-12b', 'low_cost'),
('openai-gpt-oss-20b', 'low_cost'),
('stealth-sonoma-dusk-alpha', 'low_cost'),
('meta-llama-4-scout', 'low_cost'),
('perplexity-sonar-pro', 'premium'),
('xai-grok-2-vision', 'premium'),
('google-gemini-embedding-001', 'low_cost'),
('mistral-mistral-small', 'low_cost'),
('mistral-codestral', 'mid_range'),
('google-gemini-2-5-flash-image-preview', 'mid_range'),
('zai-glm-4-5-air', 'mid_range'),
('alibaba-qwen-3-235b', 'low_cost'),
('openai-text-embedding-ada-002', 'low_cost'),
('deepseek-deepseek-r1', 'premium'),
('anthropic-claude-3-haiku', 'mid_range'),
('openai-o4-mini', 'premium'),
('openai-text-embedding-3-large', 'low_cost'),
('openai-o3', 'premium'),
('alibaba-qwen3-max', 'premium'),
('anthropic-claude-opus-4', 'premium'),
('openai-o3-mini', 'premium'),
('xai-grok-2', 'premium'),
('vercel-v0-1-5-md', 'premium'),
('anthropic-claude-3-opus', 'premium'),
('openai-gpt-4o', 'premium'),
('amazon-nova-pro', 'premium'),
('moonshotai-kimi-k2-turbo', 'premium'),
('meituan-longcat-flash-chat', 'low_cost'),
('meta-llama-3-3-70b', 'mid_range'),
('meta-llama-3-1-8b', 'low_cost'),
('vercel-v0-1-0-md', 'premium'),
('alibaba-qwen-3-14b', 'low_cost'),
('deepseek-deepseek-v3-1-thinking', 'mid_range'),
('xai-grok-3-mini-fast', 'premium'),
('morph-morph-v3-large', 'mid_range'),
('alibaba-qwen-3-30b', 'low_cost'),
('google-gemma-2-9b', 'low_cost'),
('morph-morph-v3-fast', 'mid_range'),
('amazon-nova-micro', 'low_cost'),
('openai-gpt-4-turbo', 'premium'),
('mistral-mistral-embed', 'low_cost'),
('amazon-titan-embed-text-v2', 'low_cost'),
('deepseek-deepseek-r1-distill-llama-70b', 'mid_range'),
('mistral-ministral-3b', 'low_cost'),
('alibaba-qwen-3-32b', 'low_cost'),
('mistral-mistral-large', 'premium'),
('mistral-magistral-small', 'mid_range'),
('cohere-command-a', 'premium'),
('deepseek-deepseek-v3-1-base', 'mid_range'),
('amazon-nova-lite', 'low_cost'),
('zai-glm-4-5v', 'mid_range'),
('perplexity-sonar-reasoning', 'premium'),
('meta-llama-3-2-1b', 'low_cost'),
('mistral-pixtral-large', 'premium'),
('perplexity-sonar-reasoning-pro', 'premium'),
('mistral-mixtral-8x22b-instruct', 'mid_range'),
('meta-llama-3-2-3b', 'low_cost'),
('mistral-devstral-small', 'low_cost'),
('mistral-mistral-medium', 'mid_range'),
('openai-o1', 'premium'),
('mistral-ministral-8b', 'low_cost'),
('meta-llama-3-2-90b', 'mid_range'),
('meta-llama-3-1-70b', 'mid_range'),
('inception-mercury-coder-small', 'mid_range'),
('google-text-embedding-005', 'low_cost'),
('cohere-command-r', 'low_cost'),
('mistral-magistral-medium', 'premium'),
('cohere-embed-v4-0', 'low_cost'),
('meta-llama-3-2-11b', 'low_cost'),
('cohere-command-r-plus', 'premium'),
('voyage-voyage-3-5-lite', 'low_cost'),
('voyage-voyage-code-2', 'low_cost'),
('voyage-voyage-law-2', 'low_cost'),
('voyage-voyage-finance-2', 'low_cost'),
('google-text-multilingual-embedding-002', 'low_cost'),
('voyage-voyage-3-5', 'low_cost'),
('voyage-voyage-code-3', 'low_cost'),
('voyage-voyage-3-large', 'low_cost'),
('meta-llama-3-8b', 'low_cost'),
('openai-gpt-3-5-turbo-instruct', 'mid_range'),
('meta-llama-3-70b', 'mid_range');

-- Speed dimension assignments
INSERT OR IGNORE INTO model_speed_assignments (model_id, speed_dimension_id) VALUES
('anthropic-claude-sonnet-4', 'slow'),
('openai-gpt-5', 'slow'),
('google-gemini-2-0-flash', 'instant'),
('openai-gpt-4-1-nano', 'instant'),
('openai-gpt-5-mini', 'slow'),
('google-gemini-2-5-pro', 'slow'),
('google-gemini-2-5-flash', 'instant'),
('google-gemini-2-5-flash-lite', 'instant'),
('openai-gpt-4-1', 'slow'),
('openai-text-embedding-3-small', 'slow'),
('openai-gpt-4-1-mini', 'slow'),
('anthropic-claude-3-7-sonnet', 'slow'),
('openai-gpt-5-nano', 'instant'),
('deepseek-deepseek-v3-1', 'slow'),
('openai-gpt-4o', 'fast'),
('moonshotai-kimi-k2-0905', 'slow'),
('moonshotai-kimi-k2', 'slow'),
('alibaba-qwen3-coder', 'slow'),
('anthropic-claude-opus-4-1', 'slow'),
('openai-gpt-4o-mini', 'fast'),
('openai-gpt-oss-120b', 'slow'),
('xai-grok-code-fast-1', 'fast'),
('stealth-sonoma-sky-alpha', 'slow'),
('anthropic-claude-3-5-sonnet', 'slow'),
('google-gemini-2-0-flash-lite', 'instant'),
('xai-grok-3-mini', 'slow'),
('xai-grok-4', 'slow'),
('xai-grok-3', 'slow'),
('perplexity-sonar', 'slow'),
('anthropic-claude-3-5-haiku', 'fast'),
('mistral-codestral-embed', 'slow'),
('xai-grok-3-fast', 'fast'),
('deepseek-deepseek-v3', 'fast'),
('zai-glm-4-5', 'slow'),
('meta-llama-4-maverick', 'slow'),
('openai-gpt-3-5-turbo', 'slow'),
('mistral-pixtral-12b', 'slow'),
('openai-gpt-oss-20b', 'slow'),
('stealth-sonoma-dusk-alpha', 'fast'),
('meta-llama-4-scout', 'slow'),
('perplexity-sonar-pro', 'slow'),
('xai-grok-2-vision', 'slow'),
('google-gemini-embedding-001', 'slow'),
('mistral-mistral-small', 'slow'),
('mistral-codestral', 'slow'),
('google-gemini-2-5-flash-image-preview', 'instant'),
('zai-glm-4-5-air', 'slow'),
('alibaba-qwen-3-235b', 'slow'),
('openai-text-embedding-ada-002', 'slow'),
('deepseek-deepseek-r1', 'slow'),
('anthropic-claude-3-haiku', 'fast'),
('openai-o4-mini', 'fast'),
('openai-text-embedding-3-large', 'slow'),
('openai-o3', 'slow'),
('alibaba-qwen3-max', 'slow'),
('anthropic-claude-opus-4', 'slow'),
('openai-o3-mini', 'slow'),
('xai-grok-2', 'slow'),
('vercel-v0-1-5-md', 'slow'),
('anthropic-claude-3-opus', 'slow'),
('openai-gpt-4o', 'fast'),
('amazon-nova-pro', 'slow'),
('moonshotai-kimi-k2-turbo', 'slow'),
('meituan-longcat-flash-chat', 'instant'),
('meta-llama-3-3-70b', 'slow'),
('meta-llama-3-1-8b', 'slow'),
('vercel-v0-1-0-md', 'slow'),
('alibaba-qwen-3-14b', 'slow'),
('deepseek-deepseek-v3-1-thinking', 'fast'),
('xai-grok-3-mini-fast', 'fast'),
('morph-morph-v3-large', 'fast'),
('alibaba-qwen-3-30b', 'slow'),
('google-gemma-2-9b', 'fast'),
('morph-morph-v3-fast', 'fast'),
('amazon-nova-micro', 'slow'),
('openai-gpt-4-turbo', 'slow'),
('mistral-mistral-embed', 'slow'),
('amazon-titan-embed-text-v2', 'slow'),
('deepseek-deepseek-r1-distill-llama-70b', 'slow'),
('mistral-ministral-3b', 'slow'),
('alibaba-qwen-3-32b', 'slow'),
('mistral-mistral-large', 'slow'),
('mistral-magistral-small', 'slow'),
('cohere-command-a', 'slow'),
('deepseek-deepseek-v3-1-base', 'slow'),
('amazon-nova-lite', 'instant'),
('zai-glm-4-5v', 'slow'),
('perplexity-sonar-reasoning', 'slow'),
('meta-llama-3-2-1b', 'slow'),
('mistral-pixtral-large', 'slow'),
('perplexity-sonar-reasoning-pro', 'slow'),
('mistral-mixtral-8x22b-instruct', 'slow'),
('meta-llama-3-2-3b', 'slow'),
('mistral-devstral-small', 'slow'),
('mistral-mistral-medium', 'slow'),
('openai-o1', 'slow'),
('mistral-ministral-8b', 'fast'),
('meta-llama-3-2-90b', 'slow'),
('meta-llama-3-1-70b', 'slow'),
('inception-mercury-coder-small', 'slow'),
('google-text-embedding-005', 'slow'),
('cohere-command-r', 'slow'),
('mistral-magistral-medium', 'slow'),
('cohere-embed-v4-0', 'slow'),
('meta-llama-3-2-11b', 'slow'),
('cohere-command-r-plus', 'slow'),
('voyage-voyage-3-5-lite', 'instant'),
('voyage-voyage-code-2', 'slow'),
('voyage-voyage-law-2', 'slow'),
('voyage-voyage-finance-2', 'slow'),
('google-text-multilingual-embedding-002', 'slow'),
('voyage-voyage-3-5', 'slow'),
('voyage-voyage-code-3', 'slow'),
('voyage-voyage-3-large', 'slow'),
('meta-llama-3-8b', 'fast'),
('openai-gpt-3-5-turbo-instruct', 'slow'),
('meta-llama-3-70b', 'fast');

-- Context size assignments
INSERT OR IGNORE INTO model_context_assignments (model_id, context_size_id) VALUES
('anthropic-claude-sonnet-4', 'long'),
('openai-gpt-5', 'long'),
('google-gemini-2-0-flash', 'long'),
('openai-gpt-4-1-nano', 'long'),
('openai-gpt-5-mini', 'long'),
('google-gemini-2-5-pro', 'long'),
('google-gemini-2-5-flash', 'long'),
('google-gemini-2-5-flash-lite', 'long'),
('openai-gpt-4-1', 'long'),
('openai-text-embedding-3-small', 'short'),
('openai-gpt-4-1-mini', 'long'),
('anthropic-claude-3-7-sonnet', 'long'),
('openai-gpt-5-nano', 'long'),
('deepseek-deepseek-v3-1', 'long'),
('openai-gpt-4o', 'long'),
('moonshotai-kimi-k2-0905', 'long'),
('moonshotai-kimi-k2', 'long'),
('alibaba-qwen3-coder', 'long'),
('anthropic-claude-opus-4-1', 'long'),
('openai-gpt-4o-mini', 'long'),
('openai-gpt-oss-120b', 'long'),
('xai-grok-code-fast-1', 'long'),
('stealth-sonoma-sky-alpha', 'long'),
('anthropic-claude-3-5-sonnet', 'long'),
('google-gemini-2-0-flash-lite', 'long'),
('xai-grok-3-mini', 'long'),
('xai-grok-4', 'long'),
('xai-grok-3', 'long'),
('perplexity-sonar', 'medium'),
('anthropic-claude-3-5-haiku', 'long'),
('mistral-codestral-embed', 'short'),
('xai-grok-3-fast', 'long'),
('deepseek-deepseek-v3', 'long'),
('zai-glm-4-5', 'long'),
('meta-llama-4-maverick', 'long'),
('openai-gpt-3-5-turbo', 'short'),
('mistral-pixtral-12b', 'long'),
('openai-gpt-oss-20b', 'long'),
('stealth-sonoma-dusk-alpha', 'long'),
('meta-llama-4-scout', 'long'),
('perplexity-sonar-pro', 'long'),
('xai-grok-2-vision', 'medium'),
('google-gemini-embedding-001', 'short'),
('mistral-mistral-small', 'medium'),
('mistral-codestral', 'long'),
('google-gemini-2-5-flash-image-preview', 'long'),
('zai-glm-4-5-air', 'long'),
('alibaba-qwen-3-235b', 'long'),
('openai-text-embedding-ada-002', 'short'),
('deepseek-deepseek-r1', 'long'),
('anthropic-claude-3-haiku', 'long'),
('openai-o4-mini', 'long'),
('openai-text-embedding-3-large', 'short'),
('openai-o3', 'long'),
('alibaba-qwen3-max', 'long'),
('anthropic-claude-opus-4', 'long'),
('openai-o3-mini', 'long'),
('xai-grok-2', 'long'),
('vercel-v0-1-5-md', 'long'),
('anthropic-claude-3-opus', 'long'),
('openai-gpt-4o', 'long'),
('amazon-nova-pro', 'long'),
('moonshotai-kimi-k2-turbo', 'long'),
('meituan-longcat-flash-chat', 'long'),
('meta-llama-3-3-70b', 'long'),
('meta-llama-3-1-8b', 'long'),
('vercel-v0-1-0-md', 'long'),
('alibaba-qwen-3-14b', 'medium'),
('deepseek-deepseek-v3-1-thinking', 'long'),
('xai-grok-3-mini-fast', 'long'),
('morph-morph-v3-large', 'medium'),
('alibaba-qwen-3-30b', 'medium'),
('google-gemma-2-9b', 'short'),
('morph-morph-v3-fast', 'medium'),
('amazon-nova-micro', 'long'),
('openai-gpt-4-turbo', 'long'),
('mistral-mistral-embed', 'short'),
('amazon-titan-embed-text-v2', 'short'),
('deepseek-deepseek-r1-distill-llama-70b', 'long'),
('mistral-ministral-3b', 'long'),
('alibaba-qwen-3-32b', 'long'),
('mistral-mistral-large', 'medium'),
('mistral-magistral-small', 'long'),
('cohere-command-a', 'long'),
('deepseek-deepseek-v3-1-base', 'long'),
('amazon-nova-lite', 'long'),
('zai-glm-4-5v', 'medium'),
('perplexity-sonar-reasoning', 'medium'),
('meta-llama-3-2-1b', 'long'),
('mistral-pixtral-large', 'long'),
('perplexity-sonar-reasoning-pro', 'medium'),
('mistral-mixtral-8x22b-instruct', 'medium'),
('meta-llama-3-2-3b', 'long'),
('mistral-devstral-small', 'long'),
('mistral-mistral-medium', 'long'),
('openai-o1', 'long'),
('mistral-ministral-8b', 'long'),
('meta-llama-3-2-90b', 'long'),
('meta-llama-3-1-70b', 'long'),
('inception-mercury-coder-small', 'medium'),
('google-text-embedding-005', 'short'),
('cohere-command-r', 'long'),
('mistral-magistral-medium', 'long'),
('cohere-embed-v4-0', 'short'),
('meta-llama-3-2-11b', 'long'),
('cohere-command-r-plus', 'long'),
('voyage-voyage-3-5-lite', 'short'),
('voyage-voyage-code-2', 'short'),
('voyage-voyage-law-2', 'short'),
('voyage-voyage-finance-2', 'short'),
('google-text-multilingual-embedding-002', 'short'),
('voyage-voyage-3-5', 'short'),
('voyage-voyage-code-3', 'short'),
('voyage-voyage-3-large', 'short'),
('meta-llama-3-8b', 'short'),
('openai-gpt-3-5-turbo-instruct', 'short'),
('meta-llama-3-70b', 'short');

-- Use case assignments
INSERT OR IGNORE INTO model_use_case_assignments (model_id, use_case_id) VALUES
('anthropic-claude-sonnet-4', 'coding_development'),
('anthropic-claude-sonnet-4', 'creative_multimodal'),
('openai-gpt-5', 'research_analysis'),
('openai-gpt-5', 'coding_development'),
('google-gemini-2-0-flash', 'creative_multimodal'),
('openai-gpt-4-1-nano', 'conversational'),
('openai-gpt-5-mini', 'conversational'),
('openai-gpt-5-mini', 'research_analysis'),
('google-gemini-2-5-pro', 'research_analysis'),
('google-gemini-2-5-pro', 'creative_multimodal'),
('google-gemini-2-5-flash', 'creative_multimodal'),
('google-gemini-2-5-flash-lite', 'coding_development'),
('google-gemini-2-5-flash-lite', 'creative_multimodal'),
('openai-gpt-4-1', 'conversational'),
('openai-text-embedding-3-small', 'conversational'),
('openai-gpt-4-1-mini', 'conversational'),
('anthropic-claude-3-7-sonnet', 'research_analysis'),
('anthropic-claude-3-7-sonnet', 'coding_development'),
('anthropic-claude-3-7-sonnet', 'creative_multimodal'),
('openai-gpt-5-nano', 'conversational'),
('deepseek-deepseek-v3-1', 'conversational'),
('openai-gpt-4o', 'conversational'),
('moonshotai-kimi-k2-0905', 'coding_development'),
('moonshotai-kimi-k2-0905', 'creative_multimodal'),
('moonshotai-kimi-k2', 'coding_development'),
('moonshotai-kimi-k2', 'creative_multimodal'),
('alibaba-qwen3-coder', 'coding_development'),
('alibaba-qwen3-coder', 'creative_multimodal'),
('anthropic-claude-opus-4-1', 'coding_development'),
('anthropic-claude-opus-4-1', 'creative_multimodal'),
('openai-gpt-4o-mini', 'creative_multimodal'),
('openai-gpt-oss-120b', 'research_analysis'),
('xai-grok-code-fast-1', 'coding_development'),
('stealth-sonoma-sky-alpha', 'creative_multimodal'),
('anthropic-claude-3-5-sonnet', 'creative_multimodal'),
('google-gemini-2-0-flash-lite', 'creative_multimodal'),
('xai-grok-3-mini', 'conversational'),
('xai-grok-4', 'research_analysis'),
('xai-grok-3', 'coding_development'),
('perplexity-sonar', 'conversational'),
('anthropic-claude-3-5-haiku', 'conversational'),
('mistral-codestral-embed', 'coding_development'),
('xai-grok-3-fast', 'coding_development'),
('deepseek-deepseek-v3', 'research_analysis'),
('zai-glm-4-5', 'conversational'),
('meta-llama-4-maverick', 'conversational'),
('openai-gpt-3-5-turbo', 'conversational'),
('mistral-pixtral-12b', 'creative_multimodal'),
('openai-gpt-oss-20b', 'conversational'),
('stealth-sonoma-dusk-alpha', 'creative_multimodal'),
('meta-llama-4-scout', 'conversational'),
('meta-llama-4-scout', 'research_analysis'),
('meta-llama-4-scout', 'coding_development'),
('meta-llama-4-scout', 'creative_multimodal'),
('perplexity-sonar-pro', 'conversational'),
('xai-grok-2-vision', 'research_analysis'),
('xai-grok-2-vision', 'creative_multimodal'),
('google-gemini-embedding-001', 'coding_development'),
('google-gemini-embedding-001', 'creative_multimodal'),
('mistral-mistral-small', 'conversational'),
('mistral-codestral', 'coding_development'),
('mistral-codestral', 'creative_multimodal'),
('google-gemini-2-5-flash-image-preview', 'conversational'),
('google-gemini-2-5-flash-image-preview', 'research_analysis'),
('google-gemini-2-5-flash-image-preview', 'creative_multimodal'),
('zai-glm-4-5-air', 'conversational'),
('alibaba-qwen-3-235b', 'research_analysis'),
('openai-text-embedding-ada-002', 'conversational'),
('deepseek-deepseek-r1', 'research_analysis'),
('anthropic-claude-3-haiku', 'creative_multimodal'),
('openai-o4-mini', 'research_analysis'),
('openai-o4-mini', 'coding_development'),
('openai-o4-mini', 'creative_multimodal'),
('openai-text-embedding-3-large', 'conversational'),
('openai-o3', 'research_analysis'),
('openai-o3', 'coding_development'),
('openai-o3', 'creative_multimodal'),
('alibaba-qwen3-max', 'conversational'),
('anthropic-claude-opus-4', 'coding_development'),
('openai-o3-mini', 'research_analysis'),
('xai-grok-2', 'conversational'),
('xai-grok-2', 'research_analysis'),
('xai-grok-2', 'coding_development'),
('xai-grok-2', 'creative_multimodal'),
('vercel-v0-1-5-md', 'research_analysis'),
('anthropic-claude-3-opus', 'conversational'),
('openai-gpt-4o', 'conversational'),
('amazon-nova-pro', 'creative_multimodal'),
('moonshotai-kimi-k2-turbo', 'conversational'),
('meituan-longcat-flash-chat', 'conversational'),
('meta-llama-3-3-70b', 'research_analysis'),
('meta-llama-3-3-70b', 'coding_development'),
('meta-llama-3-1-8b', 'coding_development'),
('vercel-v0-1-0-md', 'research_analysis'),
('alibaba-qwen-3-14b', 'research_analysis'),
('deepseek-deepseek-v3-1-thinking', 'research_analysis'),
('xai-grok-3-mini-fast', 'conversational'),
('morph-morph-v3-large', 'coding_development'),
('alibaba-qwen-3-30b', 'research_analysis'),
('google-gemma-2-9b', 'conversational'),
('morph-morph-v3-fast', 'coding_development'),
('amazon-nova-micro', 'conversational'),
('openai-gpt-4-turbo', 'conversational'),
('mistral-mistral-embed', 'conversational'),
('amazon-titan-embed-text-v2', 'conversational'),
('deepseek-deepseek-r1-distill-llama-70b', 'research_analysis'),
('deepseek-deepseek-r1-distill-llama-70b', 'coding_development'),
('deepseek-deepseek-r1-distill-llama-70b', 'creative_multimodal'),
('mistral-ministral-3b', 'creative_multimodal'),
('alibaba-qwen-3-32b', 'research_analysis'),
('alibaba-qwen-3-32b', 'coding_development'),
('mistral-mistral-large', 'research_analysis'),
('mistral-mistral-large', 'coding_development'),
('mistral-magistral-small', 'research_analysis'),
('cohere-command-a', 'conversational'),
('deepseek-deepseek-v3-1-base', 'conversational'),
('amazon-nova-lite', 'creative_multimodal'),
('zai-glm-4-5v', 'conversational'),
('perplexity-sonar-reasoning', 'research_analysis'),
('meta-llama-3-2-1b', 'conversational'),
('mistral-pixtral-large', 'creative_multimodal'),
('perplexity-sonar-reasoning-pro', 'research_analysis'),
('mistral-mixtral-8x22b-instruct', 'conversational'),
('meta-llama-3-2-3b', 'conversational'),
('mistral-devstral-small', 'coding_development'),
('mistral-mistral-medium', 'conversational'),
('openai-o1', 'research_analysis'),
('mistral-ministral-8b', 'conversational'),
('meta-llama-3-2-90b', 'research_analysis'),
('meta-llama-3-2-90b', 'creative_multimodal'),
('meta-llama-3-1-70b', 'research_analysis'),
('inception-mercury-coder-small', 'coding_development'),
('google-text-embedding-005', 'coding_development'),
('cohere-command-r', 'conversational'),
('mistral-magistral-medium', 'research_analysis'),
('cohere-embed-v4-0', 'creative_multimodal'),
('meta-llama-3-2-11b', 'research_analysis'),
('meta-llama-3-2-11b', 'creative_multimodal'),
('cohere-command-r-plus', 'conversational'),
('voyage-voyage-3-5-lite', 'conversational'),
('voyage-voyage-code-2', 'coding_development'),
('voyage-voyage-law-2', 'conversational'),
('voyage-voyage-finance-2', 'conversational'),
('google-text-multilingual-embedding-002', 'conversational'),
('voyage-voyage-3-5', 'conversational'),
('voyage-voyage-code-3', 'coding_development'),
('voyage-voyage-3-large', 'conversational'),
('meta-llama-3-8b', 'conversational'),
('openai-gpt-3-5-turbo-instruct', 'conversational'),
('meta-llama-3-70b', 'conversational');

-- Provider ecosystem assignments
INSERT OR IGNORE INTO model_provider_ecosystem_assignments (model_id, provider_ecosystem_id) VALUES
('anthropic-claude-sonnet-4', 'innovators'),
('openai-gpt-5', 'innovators'),
('google-gemini-2-0-flash', 'big_tech'),
('openai-gpt-4-1-nano', 'innovators'),
('openai-gpt-5-mini', 'innovators'),
('google-gemini-2-5-pro', 'big_tech'),
('google-gemini-2-5-flash', 'big_tech'),
('google-gemini-2-5-flash-lite', 'big_tech'),
('openai-gpt-4-1', 'innovators'),
('openai-text-embedding-3-small', 'innovators'),
('openai-gpt-4-1-mini', 'innovators'),
('anthropic-claude-3-7-sonnet', 'innovators'),
('openai-gpt-5-nano', 'innovators'),
('deepseek-deepseek-v3-1', 'open_source'),
('openai-gpt-4o', 'innovators'),
('moonshotai-kimi-k2-0905', 'specialists'),
('moonshotai-kimi-k2', 'specialists'),
('alibaba-qwen3-coder', 'open_source'),
('anthropic-claude-opus-4-1', 'innovators'),
('openai-gpt-4o-mini', 'innovators'),
('openai-gpt-oss-120b', 'innovators'),
('xai-grok-code-fast-1', 'innovators'),
('stealth-sonoma-sky-alpha', 'specialists'),
('anthropic-claude-3-5-sonnet', 'innovators'),
('google-gemini-2-0-flash-lite', 'big_tech'),
('xai-grok-3-mini', 'innovators'),
('xai-grok-4', 'innovators'),
('xai-grok-3', 'innovators'),
('perplexity-sonar', 'specialists'),
('anthropic-claude-3-5-haiku', 'innovators'),
('mistral-codestral-embed', 'open_source'),
('xai-grok-3-fast', 'innovators'),
('deepseek-deepseek-v3', 'open_source'),
('zai-glm-4-5', 'specialists'),
('meta-llama-4-maverick', 'big_tech'),
('openai-gpt-3-5-turbo', 'innovators'),
('mistral-pixtral-12b', 'open_source'),
('openai-gpt-oss-20b', 'innovators'),
('stealth-sonoma-dusk-alpha', 'specialists'),
('meta-llama-4-scout', 'big_tech'),
('perplexity-sonar-pro', 'specialists'),
('xai-grok-2-vision', 'innovators'),
('google-gemini-embedding-001', 'big_tech'),
('mistral-mistral-small', 'open_source'),
('mistral-codestral', 'open_source'),
('google-gemini-2-5-flash-image-preview', 'big_tech'),
('zai-glm-4-5-air', 'specialists'),
('alibaba-qwen-3-235b', 'open_source'),
('openai-text-embedding-ada-002', 'innovators'),
('deepseek-deepseek-r1', 'open_source'),
('anthropic-claude-3-haiku', 'innovators'),
('openai-o4-mini', 'innovators'),
('openai-text-embedding-3-large', 'innovators'),
('openai-o3', 'innovators'),
('alibaba-qwen3-max', 'open_source'),
('anthropic-claude-opus-4', 'innovators'),
('openai-o3-mini', 'innovators'),
('xai-grok-2', 'innovators'),
('vercel-v0-1-5-md', 'specialists'),
('anthropic-claude-3-opus', 'innovators'),
('openai-gpt-4o', 'innovators'),
('amazon-nova-pro', 'big_tech'),
('moonshotai-kimi-k2-turbo', 'specialists'),
('meituan-longcat-flash-chat', 'specialists'),
('meta-llama-3-3-70b', 'big_tech'),
('meta-llama-3-1-8b', 'big_tech'),
('vercel-v0-1-0-md', 'specialists'),
('alibaba-qwen-3-14b', 'open_source'),
('deepseek-deepseek-v3-1-thinking', 'open_source'),
('xai-grok-3-mini-fast', 'innovators'),
('morph-morph-v3-large', 'specialists'),
('alibaba-qwen-3-30b', 'open_source'),
('google-gemma-2-9b', 'big_tech'),
('morph-morph-v3-fast', 'specialists'),
('amazon-nova-micro', 'big_tech'),
('openai-gpt-4-turbo', 'innovators'),
('mistral-mistral-embed', 'open_source'),
('amazon-titan-embed-text-v2', 'big_tech'),
('deepseek-deepseek-r1-distill-llama-70b', 'open_source'),
('mistral-ministral-3b', 'open_source'),
('alibaba-qwen-3-32b', 'open_source'),
('mistral-mistral-large', 'open_source'),
('mistral-magistral-small', 'open_source'),
('cohere-command-a', 'innovators'),
('deepseek-deepseek-v3-1-base', 'open_source'),
('amazon-nova-lite', 'big_tech'),
('zai-glm-4-5v', 'specialists'),
('perplexity-sonar-reasoning', 'specialists'),
('meta-llama-3-2-1b', 'big_tech'),
('mistral-pixtral-large', 'open_source'),
('perplexity-sonar-reasoning-pro', 'specialists'),
('mistral-mixtral-8x22b-instruct', 'open_source'),
('meta-llama-3-2-3b', 'big_tech'),
('mistral-devstral-small', 'open_source'),
('mistral-mistral-medium', 'open_source'),
('openai-o1', 'innovators'),
('mistral-ministral-8b', 'open_source'),
('meta-llama-3-2-90b', 'big_tech'),
('meta-llama-3-1-70b', 'big_tech'),
('inception-mercury-coder-small', 'specialists'),
('google-text-embedding-005', 'big_tech'),
('cohere-command-r', 'innovators'),
('mistral-magistral-medium', 'open_source'),
('cohere-embed-v4-0', 'innovators'),
('meta-llama-3-2-11b', 'big_tech'),
('cohere-command-r-plus', 'innovators'),
('voyage-voyage-3-5-lite', 'specialists'),
('voyage-voyage-code-2', 'specialists'),
('voyage-voyage-law-2', 'specialists'),
('voyage-voyage-finance-2', 'specialists'),
('google-text-multilingual-embedding-002', 'big_tech'),
('voyage-voyage-3-5', 'specialists'),
('voyage-voyage-code-3', 'specialists'),
('voyage-voyage-3-large', 'specialists'),
('meta-llama-3-8b', 'big_tech'),
('openai-gpt-3-5-turbo-instruct', 'innovators'),
('meta-llama-3-70b', 'big_tech');

-- Availability mode assignments
INSERT OR IGNORE INTO model_availability_assignments (model_id, availability_mode_id) VALUES
('anthropic-claude-sonnet-4', 'online_only'),
('openai-gpt-5', 'online_only'),
('google-gemini-2-0-flash', 'online_only'),
('openai-gpt-4-1-nano', 'online_only'),
('openai-gpt-5-mini', 'online_only'),
('google-gemini-2-5-pro', 'online_only'),
('google-gemini-2-5-flash', 'online_only'),
('google-gemini-2-5-flash-lite', 'online_only'),
('openai-gpt-4-1', 'online_only'),
('openai-text-embedding-3-small', 'online_only'),
('openai-gpt-4-1-mini', 'online_only'),
('anthropic-claude-3-7-sonnet', 'online_only'),
('openai-gpt-5-nano', 'online_only'),
('deepseek-deepseek-v3-1', 'offline_capable'),
('openai-gpt-4o', 'online_only'),
('moonshotai-kimi-k2-0905', 'online_only'),
('moonshotai-kimi-k2', 'online_only'),
('alibaba-qwen3-coder', 'offline_capable'),
('anthropic-claude-opus-4-1', 'online_only'),
('openai-gpt-4o-mini', 'online_only'),
('openai-gpt-oss-120b', 'online_only'),
('xai-grok-code-fast-1', 'online_only'),
('stealth-sonoma-sky-alpha', 'online_only'),
('anthropic-claude-3-5-sonnet', 'online_only'),
('google-gemini-2-0-flash-lite', 'online_only'),
('xai-grok-3-mini', 'online_only'),
('xai-grok-4', 'online_only'),
('xai-grok-3', 'online_only'),
('perplexity-sonar', 'online_only'),
('anthropic-claude-3-5-haiku', 'online_only'),
('mistral-codestral-embed', 'offline_capable'),
('xai-grok-3-fast', 'online_only'),
('deepseek-deepseek-v3', 'offline_capable'),
('zai-glm-4-5', 'online_only'),
('meta-llama-4-maverick', 'offline_capable'),
('openai-gpt-3-5-turbo', 'online_only'),
('mistral-pixtral-12b', 'offline_capable'),
('openai-gpt-oss-20b', 'offline_capable'),
('stealth-sonoma-dusk-alpha', 'online_only'),
('meta-llama-4-scout', 'offline_capable'),
('perplexity-sonar-pro', 'online_only'),
('xai-grok-2-vision', 'online_only'),
('google-gemini-embedding-001', 'online_only'),
('mistral-mistral-small', 'offline_capable'),
('mistral-codestral', 'offline_capable'),
('google-gemini-2-5-flash-image-preview', 'offline_capable'),
('zai-glm-4-5-air', 'online_only'),
('alibaba-qwen-3-235b', 'offline_capable'),
('openai-text-embedding-ada-002', 'online_only'),
('deepseek-deepseek-r1', 'offline_capable'),
('anthropic-claude-3-haiku', 'online_only'),
('openai-o4-mini', 'online_only'),
('openai-text-embedding-3-large', 'online_only'),
('openai-o3', 'online_only'),
('alibaba-qwen3-max', 'offline_capable'),
('anthropic-claude-opus-4', 'online_only'),
('openai-o3-mini', 'online_only'),
('xai-grok-2', 'online_only'),
('vercel-v0-1-5-md', 'online_only'),
('anthropic-claude-3-opus', 'online_only'),
('openai-gpt-4o', 'online_only'),
('amazon-nova-pro', 'online_only'),
('moonshotai-kimi-k2-turbo', 'online_only'),
('meituan-longcat-flash-chat', 'online_only'),
('meta-llama-3-3-70b', 'offline_capable'),
('meta-llama-3-1-8b', 'offline_capable'),
('vercel-v0-1-0-md', 'online_only'),
('alibaba-qwen-3-14b', 'offline_capable'),
('deepseek-deepseek-v3-1-thinking', 'offline_capable'),
('xai-grok-3-mini-fast', 'online_only'),
('morph-morph-v3-large', 'online_only'),
('alibaba-qwen-3-30b', 'offline_capable'),
('google-gemma-2-9b', 'online_only'),
('morph-morph-v3-fast', 'online_only'),
('amazon-nova-micro', 'online_only'),
('openai-gpt-4-turbo', 'online_only'),
('mistral-mistral-embed', 'offline_capable'),
('amazon-titan-embed-text-v2', 'online_only'),
('deepseek-deepseek-r1-distill-llama-70b', 'offline_capable'),
('mistral-ministral-3b', 'offline_capable'),
('alibaba-qwen-3-32b', 'offline_capable'),
('mistral-mistral-large', 'offline_capable'),
('mistral-magistral-small', 'offline_capable'),
('cohere-command-a', 'online_only'),
('deepseek-deepseek-v3-1-base', 'offline_capable'),
('amazon-nova-lite', 'online_only'),
('zai-glm-4-5v', 'online_only'),
('perplexity-sonar-reasoning', 'online_only'),
('meta-llama-3-2-1b', 'offline_capable'),
('mistral-pixtral-large', 'offline_capable'),
('perplexity-sonar-reasoning-pro', 'online_only'),
('mistral-mixtral-8x22b-instruct', 'offline_capable'),
('meta-llama-3-2-3b', 'offline_capable'),
('mistral-devstral-small', 'offline_capable'),
('mistral-mistral-medium', 'offline_capable'),
('openai-o1', 'online_only'),
('mistral-ministral-8b', 'offline_capable'),
('meta-llama-3-2-90b', 'offline_capable'),
('meta-llama-3-1-70b', 'offline_capable'),
('inception-mercury-coder-small', 'online_only'),
('google-text-embedding-005', 'online_only'),
('cohere-command-r', 'online_only'),
('mistral-magistral-medium', 'offline_capable'),
('cohere-embed-v4-0', 'online_only'),
('meta-llama-3-2-11b', 'offline_capable'),
('cohere-command-r-plus', 'online_only'),
('voyage-voyage-3-5-lite', 'online_only'),
('voyage-voyage-code-2', 'online_only'),
('voyage-voyage-law-2', 'online_only'),
('voyage-voyage-finance-2', 'online_only'),
('google-text-multilingual-embedding-002', 'online_only'),
('voyage-voyage-3-5', 'online_only'),
('voyage-voyage-code-3', 'online_only'),
('voyage-voyage-3-large', 'online_only'),
('meta-llama-3-8b', 'offline_capable'),
('openai-gpt-3-5-turbo-instruct', 'online_only'),
('meta-llama-3-70b', 'offline_capable');

-- Activity status assignments
INSERT OR IGNORE INTO model_activity_assignments (model_id, activity_status_id) VALUES
('anthropic-claude-sonnet-4', 'active'),
('openai-gpt-5', 'idle'),
('google-gemini-2-0-flash', 'idle'),
('openai-gpt-4-1-nano', 'active'),
('openai-gpt-5-mini', 'idle'),
('google-gemini-2-5-pro', 'idle'),
('google-gemini-2-5-flash', 'idle'),
('google-gemini-2-5-flash-lite', 'idle'),
('openai-gpt-4-1', 'active'),
('openai-text-embedding-3-small', 'active'),
('openai-gpt-4-1-mini', 'active'),
('anthropic-claude-3-7-sonnet', 'active'),
('openai-gpt-5-nano', 'idle'),
('deepseek-deepseek-v3-1', 'active'),
('openai-gpt-4o', 'active'),
('moonshotai-kimi-k2-0905', 'active'),
('moonshotai-kimi-k2', 'active'),
('alibaba-qwen3-coder', 'active'),
('anthropic-claude-opus-4-1', 'active'),
('openai-gpt-4o-mini', 'active'),
('openai-gpt-oss-120b', 'active'),
('xai-grok-code-fast-1', 'idle'),
('stealth-sonoma-sky-alpha', 'idle'),
('anthropic-claude-3-5-sonnet', 'active'),
('google-gemini-2-0-flash-lite', 'idle'),
('xai-grok-3-mini', 'idle'),
('xai-grok-4', 'idle'),
('xai-grok-3', 'idle'),
('perplexity-sonar', 'idle'),
('anthropic-claude-3-5-haiku', 'active'),
('mistral-codestral-embed', 'idle'),
('xai-grok-3-fast', 'idle'),
('deepseek-deepseek-v3', 'active'),
('zai-glm-4-5', 'active'),
('meta-llama-4-maverick', 'active'),
('openai-gpt-3-5-turbo', 'idle'),
('mistral-pixtral-12b', 'idle'),
('openai-gpt-oss-20b', 'active'),
('stealth-sonoma-dusk-alpha', 'idle'),
('meta-llama-4-scout', 'active'),
('perplexity-sonar-pro', 'idle'),
('xai-grok-2-vision', 'idle'),
('google-gemini-embedding-001', 'active'),
('mistral-mistral-small', 'idle'),
('mistral-codestral', 'idle'),
('google-gemini-2-5-flash-image-preview', 'idle'),
('zai-glm-4-5-air', 'idle'),
('alibaba-qwen-3-235b', 'active'),
('openai-text-embedding-ada-002', 'active'),
('deepseek-deepseek-r1', 'active'),
('anthropic-claude-3-haiku', 'active'),
('openai-o4-mini', 'active'),
('openai-text-embedding-3-large', 'active'),
('openai-o3', 'idle'),
('alibaba-qwen3-max', 'idle'),
('anthropic-claude-opus-4', 'active'),
('openai-o3-mini', 'active'),
('xai-grok-2', 'idle'),
('vercel-v0-1-5-md', 'idle'),
('anthropic-claude-3-opus', 'active'),
('openai-gpt-4o', 'active'),
('amazon-nova-pro', 'idle'),
('moonshotai-kimi-k2-turbo', 'idle'),
('meituan-longcat-flash-chat', 'idle'),
('meta-llama-3-3-70b', 'active'),
('meta-llama-3-1-8b', 'active'),
('vercel-v0-1-0-md', 'idle'),
('alibaba-qwen-3-14b', 'idle'),
('deepseek-deepseek-v3-1-thinking', 'idle'),
('xai-grok-3-mini-fast', 'idle'),
('morph-morph-v3-large', 'idle'),
('alibaba-qwen-3-30b', 'idle'),
('google-gemma-2-9b', 'idle'),
('morph-morph-v3-fast', 'idle'),
('amazon-nova-micro', 'idle'),
('openai-gpt-4-turbo', 'idle'),
('mistral-mistral-embed', 'idle'),
('amazon-titan-embed-text-v2', 'idle'),
('deepseek-deepseek-r1-distill-llama-70b', 'active'),
('mistral-ministral-3b', 'idle'),
('alibaba-qwen-3-32b', 'active'),
('mistral-mistral-large', 'idle'),
('mistral-magistral-small', 'idle'),
('cohere-command-a', 'idle'),
('deepseek-deepseek-v3-1-base', 'idle'),
('amazon-nova-lite', 'idle'),
('zai-glm-4-5v', 'active'),
('perplexity-sonar-reasoning', 'idle'),
('meta-llama-3-2-1b', 'idle'),
('mistral-pixtral-large', 'idle'),
('perplexity-sonar-reasoning-pro', 'idle'),
('mistral-mixtral-8x22b-instruct', 'idle'),
('meta-llama-3-2-3b', 'idle'),
('mistral-devstral-small', 'idle'),
('mistral-mistral-medium', 'idle'),
('openai-o1', 'active'),
('mistral-ministral-8b', 'idle'),
('meta-llama-3-2-90b', 'idle'),
('meta-llama-3-1-70b', 'idle'),
('inception-mercury-coder-small', 'idle'),
('google-text-embedding-005', 'idle'),
('cohere-command-r', 'idle'),
('mistral-magistral-medium', 'idle'),
('cohere-embed-v4-0', 'idle'),
('meta-llama-3-2-11b', 'idle'),
('cohere-command-r-plus', 'idle'),
('voyage-voyage-3-5-lite', 'idle'),
('voyage-voyage-code-2', 'idle'),
('voyage-voyage-law-2', 'idle'),
('voyage-voyage-finance-2', 'idle'),
('google-text-multilingual-embedding-002', 'idle'),
('voyage-voyage-3-5', 'idle'),
('voyage-voyage-code-3', 'idle'),
('voyage-voyage-3-large', 'idle'),
('meta-llama-3-8b', 'idle'),
('openai-gpt-3-5-turbo-instruct', 'idle'),
('meta-llama-3-70b', 'idle');

-- API usage pattern assignments
INSERT OR IGNORE INTO model_api_pattern_assignments (model_id, api_pattern_id) VALUES
('anthropic-claude-sonnet-4', 'weekly_analysts'),
('openai-gpt-5', 'weekly_analysts'),
('google-gemini-2-0-flash', 'daily_workers'),
('openai-gpt-4-1-nano', 'hourly_users'),
('openai-gpt-5-mini', 'weekly_analysts'),
('google-gemini-2-5-pro', 'weekly_analysts'),
('google-gemini-2-5-flash', 'weekly_analysts'),
('google-gemini-2-5-flash-lite', 'hourly_users'),
('openai-gpt-4-1', 'weekly_analysts'),
('openai-text-embedding-3-small', 'hourly_users'),
('openai-gpt-4-1-mini', 'daily_workers'),
('anthropic-claude-3-7-sonnet', 'weekly_analysts'),
('openai-gpt-5-nano', 'hourly_users'),
('deepseek-deepseek-v3-1', 'daily_workers'),
('openai-gpt-4o', 'weekly_analysts'),
('moonshotai-kimi-k2-0905', 'daily_workers'),
('moonshotai-kimi-k2', 'weekly_analysts'),
('alibaba-qwen3-coder', 'daily_workers'),
('anthropic-claude-opus-4-1', 'weekly_analysts'),
('openai-gpt-4o-mini', 'daily_workers'),
('openai-gpt-oss-120b', 'daily_workers'),
('xai-grok-code-fast-1', 'daily_workers'),
('stealth-sonoma-sky-alpha', 'hourly_users'),
('anthropic-claude-3-5-sonnet', 'weekly_analysts'),
('google-gemini-2-0-flash-lite', 'hourly_users'),
('xai-grok-3-mini', 'daily_workers'),
('xai-grok-4', 'weekly_analysts'),
('xai-grok-3', 'weekly_analysts'),
('perplexity-sonar', 'daily_workers'),
('anthropic-claude-3-5-haiku', 'weekly_analysts'),
('mistral-codestral-embed', 'hourly_users'),
('xai-grok-3-fast', 'weekly_analysts'),
('deepseek-deepseek-v3', 'daily_workers'),
('zai-glm-4-5', 'weekly_analysts'),
('meta-llama-4-maverick', 'daily_workers'),
('openai-gpt-3-5-turbo', 'daily_workers'),
('mistral-pixtral-12b', 'daily_workers'),
('openai-gpt-oss-20b', 'daily_workers'),
('stealth-sonoma-dusk-alpha', 'hourly_users'),
('meta-llama-4-scout', 'daily_workers'),
('perplexity-sonar-pro', 'weekly_analysts'),
('xai-grok-2-vision', 'weekly_analysts'),
('google-gemini-embedding-001', 'hourly_users'),
('mistral-mistral-small', 'daily_workers'),
('mistral-codestral', 'daily_workers'),
('google-gemini-2-5-flash-image-preview', 'weekly_analysts'),
('zai-glm-4-5-air', 'daily_workers'),
('alibaba-qwen-3-235b', 'daily_workers'),
('openai-text-embedding-ada-002', 'hourly_users'),
('deepseek-deepseek-r1', 'weekly_analysts'),
('anthropic-claude-3-haiku', 'daily_workers'),
('openai-o4-mini', 'weekly_analysts'),
('openai-text-embedding-3-large', 'hourly_users'),
('openai-o3', 'weekly_analysts'),
('alibaba-qwen3-max', 'weekly_analysts'),
('anthropic-claude-opus-4', 'weekly_analysts'),
('openai-o3-mini', 'weekly_analysts'),
('xai-grok-2', 'weekly_analysts'),
('vercel-v0-1-5-md', 'weekly_analysts'),
('anthropic-claude-3-opus', 'weekly_analysts'),
('openai-gpt-4o', 'weekly_analysts'),
('amazon-nova-pro', 'weekly_analysts'),
('moonshotai-kimi-k2-turbo', 'weekly_analysts'),
('meituan-longcat-flash-chat', 'hourly_users'),
('meta-llama-3-3-70b', 'daily_workers'),
('meta-llama-3-1-8b', 'hourly_users'),
('vercel-v0-1-0-md', 'weekly_analysts'),
('alibaba-qwen-3-14b', 'daily_workers'),
('deepseek-deepseek-v3-1-thinking', 'weekly_analysts'),
('xai-grok-3-mini-fast', 'weekly_analysts'),
('morph-morph-v3-large', 'weekly_analysts'),
('alibaba-qwen-3-30b', 'daily_workers'),
('google-gemma-2-9b', 'daily_workers'),
('morph-morph-v3-fast', 'daily_workers'),
('amazon-nova-micro', 'hourly_users'),
('openai-gpt-4-turbo', 'weekly_analysts'),
('mistral-mistral-embed', 'hourly_users'),
('amazon-titan-embed-text-v2', 'hourly_users'),
('deepseek-deepseek-r1-distill-llama-70b', 'daily_workers'),
('mistral-ministral-3b', 'hourly_users'),
('alibaba-qwen-3-32b', 'daily_workers'),
('mistral-mistral-large', 'weekly_analysts'),
('mistral-magistral-small', 'daily_workers'),
('cohere-command-a', 'weekly_analysts'),
('deepseek-deepseek-v3-1-base', 'daily_workers'),
('amazon-nova-lite', 'hourly_users'),
('zai-glm-4-5v', 'weekly_analysts'),
('perplexity-sonar-reasoning', 'weekly_analysts'),
('meta-llama-3-2-1b', 'daily_workers'),
('mistral-pixtral-large', 'weekly_analysts'),
('perplexity-sonar-reasoning-pro', 'weekly_analysts'),
('mistral-mixtral-8x22b-instruct', 'weekly_analysts'),
('meta-llama-3-2-3b', 'daily_workers'),
('mistral-devstral-small', 'daily_workers'),
('mistral-mistral-medium', 'weekly_analysts'),
('openai-o1', 'weekly_analysts'),
('mistral-ministral-8b', 'daily_workers'),
('meta-llama-3-2-90b', 'daily_workers'),
('meta-llama-3-1-70b', 'daily_workers'),
('inception-mercury-coder-small', 'daily_workers'),
('google-text-embedding-005', 'hourly_users'),
('cohere-command-r', 'daily_workers'),
('mistral-magistral-medium', 'weekly_analysts'),
('cohere-embed-v4-0', 'hourly_users'),
('meta-llama-3-2-11b', 'daily_workers'),
('cohere-command-r-plus', 'weekly_analysts'),
('voyage-voyage-3-5-lite', 'hourly_users'),
('voyage-voyage-code-2', 'hourly_users'),
('voyage-voyage-law-2', 'hourly_users'),
('voyage-voyage-finance-2', 'hourly_users'),
('google-text-multilingual-embedding-002', 'hourly_users'),
('voyage-voyage-3-5', 'hourly_users'),
('voyage-voyage-code-3', 'hourly_users'),
('voyage-voyage-3-large', 'hourly_users'),
('meta-llama-3-8b', 'hourly_users'),
('openai-gpt-3-5-turbo-instruct', 'weekly_analysts'),
('meta-llama-3-70b', 'daily_workers');

-- Emerging category assignments
INSERT OR IGNORE INTO model_emerging_category_assignments (model_id, emerging_category_id) VALUES
('openai-gpt-5', 'future_proof'),
('google-gemini-2-0-flash', 'global_scale'),
('openai-gpt-4-1-nano', 'future_proof'),
('openai-gpt-5-mini', 'future_proof'),
('google-gemini-2-5-pro', 'future_proof'),
('google-gemini-2-5-pro', 'global_scale'),
('google-gemini-2-5-flash', 'future_proof'),
('google-gemini-2-5-flash', 'global_scale'),
('google-gemini-2-5-flash-lite', 'future_proof'),
('google-gemini-2-5-flash-lite', 'global_scale'),
('openai-gpt-4-1', 'future_proof'),
('openai-gpt-4-1-mini', 'future_proof'),
('openai-gpt-5-nano', 'future_proof'),
('moonshotai-kimi-k2-0905', 'future_proof'),
('anthropic-claude-opus-4-1', 'future_proof'),
('openai-gpt-4o-mini', 'future_proof'),
('anthropic-claude-3-5-sonnet', 'future_proof'),
('anthropic-claude-3-5-sonnet', 'global_scale'),
('anthropic-claude-3-5-sonnet', 'industrial_grade'),
('google-gemini-2-0-flash-lite', 'global_scale'),
('xai-grok-3', 'industrial_grade'),
('anthropic-claude-3-5-haiku', 'future_proof'),
('xai-grok-3-fast', 'industrial_grade'),
('zai-glm-4-5', 'future_proof'),
('openai-gpt-3-5-turbo', 'future_proof'),
('perplexity-sonar-pro', 'future_proof'),
('google-gemini-embedding-001', 'global_scale'),
('google-gemini-2-5-flash-image-preview', 'future_proof'),
('google-gemini-2-5-flash-image-preview', 'global_scale'),
('zai-glm-4-5-air', 'future_proof'),
('alibaba-qwen-3-235b', 'future_proof'),
('anthropic-claude-3-haiku', 'industrial_grade'),
('xai-grok-2', 'future_proof'),
('vercel-v0-1-5-md', 'future_proof'),
('google-gemma-2-9b', 'global_scale'),
('alibaba-qwen-3-32b', 'future_proof'),
('alibaba-qwen-3-32b', 'industrial_grade'),
('zai-glm-4-5v', 'future_proof'),
('google-text-embedding-005', 'future_proof'),
('google-text-embedding-005', 'global_scale'),
('cohere-command-r', 'industrial_grade'),
('cohere-command-r-plus', 'industrial_grade'),
('voyage-voyage-3-5-lite', 'future_proof'),
('google-text-multilingual-embedding-002', 'global_scale'),
('voyage-voyage-3-5', 'future_proof'),
('openai-gpt-3-5-turbo-instruct', 'future_proof');